{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Vulnerability Index (FVI) Data Preparation\n",
    "This notebook imports socioeconomic and physical data for FVI assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, QuantileTransformer\n",
    "import fhv\n",
    "from tabula import read_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load demographic and socio-economic data\n",
    "This section imports a variety of demographic and socio-economic data from multiple sources:\n",
    "- [Bangladesh Bureau of Statistics (BBS)](http://203.112.218.65:8008/) 2011 census data downloaded from [BBS-REDATAM](http://203.112.218.69/binbgd/RpWebEngine.exe/Portal).\n",
    "- [Bangladesh 2010 Poverty Maps (Zila Upazila)](http://203.112.218.65:8008/WebTestApplication/userfiles/Image/LatestReports/Bangladesh_ZilaUpazila_pov_est_2010.pdf) is obtained from [BBS Income, Expenditure & Poverty](http://203.112.218.65:8008/PageWebMenuContent.aspx?MenuKey=366)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_name = [['PAGE5','pos','person','demographic','Percent of children under 5 years','BBS 2011'],\n",
    "               ['PAGE65','pos','person','demographic','Percent of elder population (65+ years)','BBS 2011'],\n",
    "               ['PFEMALE','pos','person','demographic','Percent of females','BBS 2011'],\n",
    "               ['PRURAL','pos','house','built','Percent of households in rural areas','BBS 2011'], \n",
    "               ['PWEAKBUILT','pos','house','built','Percent of households with weak materials','BBS 2011'],\n",
    "               ['PNOWATER','pos','house','built','Percent of households without public water supply','BBS 2011'],\n",
    "               ['PNOSANITARY','pos','house','built','ercent of households without sanitary facilities','BBS 2011'],\n",
    "               ['PNOELEC','pos','house','built','Percent of households without electricity','BBS 2011'],\n",
    "               ['PDISABL','pos','person','social','Percent of population with any sort of disability','BBS 2011'],\n",
    "               ['PLITERACY','pos','person','social','Percent of population who cannot read and write','BBS 2011'],\n",
    "               ['PETHNIC','pos','person','social','Percent of ethnic population','BBS 2011'],\n",
    "               ['PRENT','pos','house','social','Percent of rented houses','BBS 2011'],\n",
    "               ['PNOEMPLOY','pos','person','economic','Percent of population without employment','BBS 2011'],\n",
    "               ['PAGRICULT','pos','person','economic','Percent of population with agricultural jobs','BBS 2011'],\n",
    "               ['PPOOR','pos','house','economic','Percentage of population below the upper poverty line','BBS 2010'],\n",
    "               ['PPOOREXTR','pos','house','economic','Percentage of population below the lower povery line','BBS 2010'],\n",
    "               ['PNOPRIEDU','pos','person','education','Percent of population who don''t attain a primary education','BBS 2011'],\n",
    "               ['PNOCOLLEGE','pos','person','education','Percent of population who don''t attain a college education','BBS 2011']\n",
    "              ]\n",
    "census_name = pd.DataFrame(census_name, columns=['Name','Sign','Type','Group','Description','Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPULATION DATA\n",
    "df = fhv.LoadCensusBBS('./data/census2011/age 5 years group.xls')\n",
    "popu = df.sum(axis=1)\n",
    "###\n",
    "# CARIBRATE POPULATION \n",
    "###\n",
    "census = pd.DataFrame(index=df.index)\n",
    "census.index.name = 'UID'\n",
    "census['UID4'] = census.index % 10000   # Add a column of the last 4 digits of UID\n",
    "# - PAGE5: Percent of children under 5 years\n",
    "census['PAGE5'] = df[df.columns[0]]/df.sum(axis=1)\n",
    "# - PAGE65: Percent of elderly population (65+ years)\n",
    "census['PAGE65'] = df[df.columns[14:]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PFEMALE: Percent of females\n",
    "df = fhv.LoadCensusBBS('./data/census2011/sex.xls')\n",
    "census['PFEMALE'] = df['Female']/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# BUILT ENVIRONMENT\n",
    "# - PRURAL: Percent of households in rural areas\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Area of Residence.xls')\n",
    "census['PRURAL'] = df['Rural']/df.sum(axis=1)\n",
    "# - PWEAKBUILT: Percent of households with weak materials\n",
    "# (#house_Kutcha_and_Jhupri / #house_total)\n",
    "# *Pucca means high quality materials (e.g., cement or RCC)\n",
    "# *Kutcha & Jhupri means weaker materials (e.g., mud, clay, lime, or thatched)\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Type of House.xls')\n",
    "census['PWEAKBUILT'] = df[['Pucca','Semi-pucca']].sum(axis=1)/df.sum(1)\n",
    "# - PNOWATER: Percent of households without public water supply\n",
    "# *This includes \"Other\", excluding \"Tap\" and \"Tube-well\" water supply\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Source of Drinking Water.xls')\n",
    "census['PNOWATER'] = df[df.columns[-1]]/df.sum(axis=1)\n",
    "# - PNOSANITARY: Percent of households without sanitary facilities\n",
    "# *This includes \"Non-Sanitary\" and \"None\" and excludes \n",
    "# *\"Sanitary (with Water Seal)\" and \"Sanitary (no Water Seal)\"\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Toilet Facilities.xls')\n",
    "census['PNOSANITARY'] = df[df.columns[2:]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PNOELEC: Percent household without electricity\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Electricity Connection.xls')\n",
    "census['PNOELEC'] = df['No']/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# SOCIAL\n",
    "# - PDISABL: Percent of population with disability\n",
    "# *This includes all kinds of disabilities (Speech, Vision, Hearing, Physical, Mental, Autistic)\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Disability.xls')\n",
    "census['PDISABL'] = df[df.columns[1:]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PLITERACY: Percent of population who cannot read and write\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Literacy.xls')\n",
    "census['PLITERACY'] = df['No']/df.sum(axis=1)\n",
    "# - PETHNIC: Percent of ethnic population \n",
    "df = fhv.LoadCensusBBS('./data/census2011/Ethnic Population.xls')\n",
    "census['PETHNIC'] = df['Yes']/df.sum(axis=1)\n",
    "# - PRENT: Percent of rented houses\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Tenancy.xls')\n",
    "census['PRENT'] = df[['Rented', 'Rent-free']].sum(axis=1)/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# EDUCATION\n",
    "# - PNOPRIEDU: Percent of population who dont complete primary education\n",
    "# *BGD's primary education is ClassI-ClassV\n",
    "# *https://en.wikipedia.org/wiki/Education_in_Bangladesh#/media/File:BangEduSys.png\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Educational Attainment.xls')\n",
    "census['PNOPRIEDU'] = df[df.columns[:5]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PNOCOLLEGE: Percent of population who don't attend college\n",
    "census['PNOCOLLEGE'] = df[df.columns[:-4]].sum(axis=1)/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# EMPLOYMENT\n",
    "# - PNOEMPLOY: Percent of population without employment\n",
    "# *This includes \"Employed\" and \"Household Work\" and excludes \"Looking For Job\" and \"Do Not Work\"\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Activity Status.xls')\n",
    "census['PNOEMPLOY'] = df[['Looking For Job','Do Not Work']].sum(axis=1)/df.sum(axis=1)\n",
    "# - PAGRICULT : Percent of population with agricultural jobs\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Employment Field.xls')\n",
    "census['PAGRICULT'] = df['Agriculture']/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# POVERTY\n",
    "# Read PDF document and obtain data\n",
    "df = read_pdf('./data/socioecon/Bangladesh_ZilaUpazila_pov_est_2010.pdf', \n",
    "             pages=list(range(3,13)), multiple_tables=False,\n",
    "             pandas_options={'header': None, 'skiprows':2})\n",
    "df.columns = ['zl-code','zila-name','UID4','upz-name','PPOOREXTR','PPOOR']\n",
    "df = df.drop(['zl-code','zila-name','upz-name'], axis=1)\n",
    "# Percentage to decimal\n",
    "df[['PPOOREXTR','PPOOR']] = df[['PPOOREXTR','PPOOR']]/100\n",
    "# Here we use only 4 upazila code to match with census UID, since all 4 digits are unique! Which means\n",
    "assert len(np.unique(census.index % 10000)) == len(np.unique(df['UID4']))\n",
    "# Sorting by UID4\n",
    "df = df.set_index('UID4').sort_index()\n",
    "# Merging\n",
    "census = census.reset_index().merge(df, on='UID4').set_index('UID').drop('UID4',axis=1)\n",
    "census = census[census_name['Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomalization and Save variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAGE5</th>\n",
       "      <th>PAGE65</th>\n",
       "      <th>PFEMALE</th>\n",
       "      <th>PRURAL</th>\n",
       "      <th>PWEAKBUILT</th>\n",
       "      <th>PNOWATER</th>\n",
       "      <th>PNOSANITARY</th>\n",
       "      <th>PNOELEC</th>\n",
       "      <th>PDISABL</th>\n",
       "      <th>PLITERACY</th>\n",
       "      <th>PETHNIC</th>\n",
       "      <th>PRENT</th>\n",
       "      <th>PNOEMPLOY</th>\n",
       "      <th>PAGRICULT</th>\n",
       "      <th>PPOOR</th>\n",
       "      <th>PPOOREXTR</th>\n",
       "      <th>PNOPRIEDU</th>\n",
       "      <th>PNOCOLLEGE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100409</td>\n",
       "      <td>0.103249</td>\n",
       "      <td>0.040339</td>\n",
       "      <td>0.511939</td>\n",
       "      <td>0.919587</td>\n",
       "      <td>0.053392</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.330364</td>\n",
       "      <td>0.783000</td>\n",
       "      <td>0.020299</td>\n",
       "      <td>0.472155</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.067313</td>\n",
       "      <td>0.334860</td>\n",
       "      <td>0.722824</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.541183</td>\n",
       "      <td>0.962848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100419</td>\n",
       "      <td>0.095860</td>\n",
       "      <td>0.039666</td>\n",
       "      <td>0.504324</td>\n",
       "      <td>0.908695</td>\n",
       "      <td>0.068895</td>\n",
       "      <td>0.020730</td>\n",
       "      <td>0.166402</td>\n",
       "      <td>0.704202</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.388951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026309</td>\n",
       "      <td>0.329836</td>\n",
       "      <td>0.601251</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.421312</td>\n",
       "      <td>0.948729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100428</td>\n",
       "      <td>0.097443</td>\n",
       "      <td>0.040805</td>\n",
       "      <td>0.508003</td>\n",
       "      <td>0.881363</td>\n",
       "      <td>0.092098</td>\n",
       "      <td>0.050962</td>\n",
       "      <td>0.268048</td>\n",
       "      <td>0.680701</td>\n",
       "      <td>0.020743</td>\n",
       "      <td>0.413562</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.097429</td>\n",
       "      <td>0.345242</td>\n",
       "      <td>0.561402</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.444761</td>\n",
       "      <td>0.939851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100447</td>\n",
       "      <td>0.093653</td>\n",
       "      <td>0.044466</td>\n",
       "      <td>0.516130</td>\n",
       "      <td>0.886505</td>\n",
       "      <td>0.071055</td>\n",
       "      <td>0.048994</td>\n",
       "      <td>0.218788</td>\n",
       "      <td>0.648306</td>\n",
       "      <td>0.018080</td>\n",
       "      <td>0.398837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051930</td>\n",
       "      <td>0.367495</td>\n",
       "      <td>0.607921</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.432513</td>\n",
       "      <td>0.942979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100485</td>\n",
       "      <td>0.098751</td>\n",
       "      <td>0.044111</td>\n",
       "      <td>0.508659</td>\n",
       "      <td>0.828357</td>\n",
       "      <td>0.060392</td>\n",
       "      <td>0.436741</td>\n",
       "      <td>0.223187</td>\n",
       "      <td>0.688012</td>\n",
       "      <td>0.022614</td>\n",
       "      <td>0.395149</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.102425</td>\n",
       "      <td>0.325537</td>\n",
       "      <td>0.638243</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.425012</td>\n",
       "      <td>0.954199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609141</td>\n",
       "      <td>0.150547</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>0.499579</td>\n",
       "      <td>0.978997</td>\n",
       "      <td>0.195637</td>\n",
       "      <td>0.542778</td>\n",
       "      <td>0.795591</td>\n",
       "      <td>0.686969</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>0.672957</td>\n",
       "      <td>0.008522</td>\n",
       "      <td>0.055613</td>\n",
       "      <td>0.403099</td>\n",
       "      <td>0.662260</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.725874</td>\n",
       "      <td>0.982873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609153</td>\n",
       "      <td>0.143152</td>\n",
       "      <td>0.030035</td>\n",
       "      <td>0.500637</td>\n",
       "      <td>0.945791</td>\n",
       "      <td>0.282478</td>\n",
       "      <td>0.283740</td>\n",
       "      <td>0.587684</td>\n",
       "      <td>0.593275</td>\n",
       "      <td>0.014548</td>\n",
       "      <td>0.588482</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0.093185</td>\n",
       "      <td>0.405466</td>\n",
       "      <td>0.527961</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.663757</td>\n",
       "      <td>0.974846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609159</td>\n",
       "      <td>0.137528</td>\n",
       "      <td>0.028306</td>\n",
       "      <td>0.510098</td>\n",
       "      <td>0.898787</td>\n",
       "      <td>0.385117</td>\n",
       "      <td>0.746354</td>\n",
       "      <td>0.581728</td>\n",
       "      <td>0.565562</td>\n",
       "      <td>0.014551</td>\n",
       "      <td>0.564579</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>0.427244</td>\n",
       "      <td>0.631287</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.626126</td>\n",
       "      <td>0.976171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609162</td>\n",
       "      <td>0.105126</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.473312</td>\n",
       "      <td>0.332392</td>\n",
       "      <td>0.741495</td>\n",
       "      <td>0.046615</td>\n",
       "      <td>0.218020</td>\n",
       "      <td>0.132115</td>\n",
       "      <td>0.010691</td>\n",
       "      <td>0.387067</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>0.579076</td>\n",
       "      <td>0.391028</td>\n",
       "      <td>0.101994</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.433749</td>\n",
       "      <td>0.875801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609194</td>\n",
       "      <td>0.125425</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>0.505122</td>\n",
       "      <td>0.912980</td>\n",
       "      <td>0.399847</td>\n",
       "      <td>0.522689</td>\n",
       "      <td>0.508410</td>\n",
       "      <td>0.692241</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>0.506054</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.031839</td>\n",
       "      <td>0.431266</td>\n",
       "      <td>0.492077</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.541673</td>\n",
       "      <td>0.968220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           PAGE5    PAGE65   PFEMALE    PRURAL  PWEAKBUILT  PNOWATER  \\\n",
       "UID                                                                    \n",
       "100409  0.103249  0.040339  0.511939  0.919587    0.053392  0.019316   \n",
       "100419  0.095860  0.039666  0.504324  0.908695    0.068895  0.020730   \n",
       "100428  0.097443  0.040805  0.508003  0.881363    0.092098  0.050962   \n",
       "100447  0.093653  0.044466  0.516130  0.886505    0.071055  0.048994   \n",
       "100485  0.098751  0.044111  0.508659  0.828357    0.060392  0.436741   \n",
       "...          ...       ...       ...       ...         ...       ...   \n",
       "609141  0.150547  0.026528  0.499579  0.978997    0.195637  0.542778   \n",
       "609153  0.143152  0.030035  0.500637  0.945791    0.282478  0.283740   \n",
       "609159  0.137528  0.028306  0.510098  0.898787    0.385117  0.746354   \n",
       "609162  0.105126  0.023166  0.473312  0.332392    0.741495  0.046615   \n",
       "609194  0.125425  0.029337  0.505122  0.912980    0.399847  0.522689   \n",
       "\n",
       "        PNOSANITARY   PNOELEC   PDISABL  PLITERACY   PETHNIC     PRENT  \\\n",
       "UID                                                                      \n",
       "100409     0.330364  0.783000  0.020299   0.472155  0.004445  0.067313   \n",
       "100419     0.166402  0.704202  0.023943   0.388951  0.000000  0.026309   \n",
       "100428     0.268048  0.680701  0.020743   0.413562  0.000741  0.097429   \n",
       "100447     0.218788  0.648306  0.018080   0.398837  0.000000  0.051930   \n",
       "100485     0.223187  0.688012  0.022614   0.395149  0.000023  0.102425   \n",
       "...             ...       ...       ...        ...       ...       ...   \n",
       "609141     0.795591  0.686969  0.011467   0.672957  0.008522  0.055613   \n",
       "609153     0.587684  0.593275  0.014548   0.588482  0.011797  0.093185   \n",
       "609159     0.581728  0.565562  0.014551   0.564579  0.001018  0.031226   \n",
       "609162     0.218020  0.132115  0.010691   0.387067  0.007786  0.579076   \n",
       "609194     0.508410  0.692241  0.016897   0.506054  0.000173  0.031839   \n",
       "\n",
       "        PNOEMPLOY  PAGRICULT  PPOOR  PPOOREXTR  PNOPRIEDU  PNOCOLLEGE  \n",
       "UID                                                                    \n",
       "100409   0.334860   0.722824  0.228      0.120   0.541183    0.962848  \n",
       "100419   0.329836   0.601251  0.171      0.089   0.421312    0.948729  \n",
       "100428   0.345242   0.561402  0.192      0.099   0.444761    0.939851  \n",
       "100447   0.367495   0.607921  0.196      0.103   0.432513    0.942979  \n",
       "100485   0.325537   0.638243  0.129      0.061   0.425012    0.954199  \n",
       "...           ...        ...    ...        ...        ...         ...  \n",
       "609141   0.403099   0.662260  0.526      0.465   0.725874    0.982873  \n",
       "609153   0.405466   0.527961  0.347      0.289   0.663757    0.974846  \n",
       "609159   0.427244   0.631287  0.458      0.397   0.626126    0.976171  \n",
       "609162   0.391028   0.101994  0.143      0.097   0.433749    0.875801  \n",
       "609194   0.431266   0.492077  0.390      0.329   0.541673    0.968220  \n",
       "\n",
       "[544 rows x 18 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort \n",
    "\n",
    "\n",
    "# Flip signs of the indicators\n",
    "for index, row in data_name.iterrows():\n",
    "    if row['Sign'] == 'neg':\n",
    "        data[row['Name']] = -data[row['Name']].values\n",
    "    elif row['Sign'] == 'pos':\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"problem\")\n",
    "# Scaling to 0-1 with Max/Min values\n",
    "scaler = MinMaxScaler()\n",
    "data[data.columns] = scaler.fit_transform(data[data.columns])\n",
    "\n",
    "# Save data\n",
    "if True:\n",
    "    fn = './data/census.hdf'\n",
    "    census.to_hdf(fn, 'data')\n",
    "    print('%s is saved.' % fn)\n",
    "    fn = './data/census_table.hdf'\n",
    "    census_name.to_hdf(fn, 'name')\n",
    "    print('%s is saved.' % fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load physical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load code4 and code3\n",
    "fn = os.path.join('land', 'boundary_gadm', 'gadm4_code.tif')\n",
    "ds = gdal.Open(fn); dsCopy = ds\n",
    "code4 = ds.GetRasterBand(1).ReadAsArray()\n",
    "code3 = np.floor(code4/100)\n",
    "nocode = (code4 == code4[0,0])\n",
    "\n",
    "# Load census data\n",
    "cens = np.load('data_census.npy'); cens = cens.item()\n",
    "pop = cens['pop']\n",
    "\n",
    "\n",
    "#%% Load variables\n",
    "# Proximity to rivers (priv, 0-1)\n",
    "# (1km:1, 2km:0.5, 3km:0.2, 4+km:0)\n",
    "loc = './hydrology/river_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv = np.zeros(data.shape)\n",
    "priv[data != data[0,0]] = 2\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 5\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 10\n",
    "# - Scale to 0-1\n",
    "priv = fh.zeroToOne(priv)\n",
    "fh.evaluation('priv', priv, code4)\n",
    "\n",
    "# Proximity to cyclone shelters (pcsh, 0-1)\n",
    "# (1km:0, 2km:0.33, 3km:0.67, 4+km:1)\n",
    "loc = './hydrology/shelters_cyclone_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh = np.ones(data.shape)\n",
    "pcsh[data != data[0,0]] = 2/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 1/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "pcsh = fh.zeroToOne(pcsh)\n",
    "fh.evaluation('pcsh', pcsh, code4)\n",
    "\n",
    "# Number of cyclone shelters per Upazila capita (ncsh, 0-1)\n",
    "# (#shelters in Upazila / #pop in Upazila)\n",
    "fn = os.path.join(os.path.join('hydrology','shelters_cyclone',\n",
    "                               'cyclone_shelters_gadam4.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('cyclone_shelters_gadam4')\n",
    "#cshel_cc4 = df.Div_ID*10**6 + df.Dist_ID*10**4+df.Upz_ID*10**2+df.Un_ID\n",
    "cshel_cc3 = df.Div_ID*10**4 + df.Dist_ID*10**2+df.Upz_ID\n",
    "count = cshel_cc3.value_counts()\n",
    "ncsh = np.empty(code3.shape); ncsh[:] = 0\n",
    "for index, row in count.iteritems():\n",
    "    ncsh[code3 == index] = row/pop[pop[:,0] == index,1]\n",
    "# - Scale to 0-1\n",
    "ncsh = 1 - fh.zeroToOne(ncsh)\n",
    "fh.evaluation('ncsh', ncsh, code4)\n",
    "\n",
    "# Number of PHC and Hospitals\n",
    "fn = os.path.join(os.path.join('health','healthsites_lged', 'gadm4_join.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('gadm4_join')\n",
    "# - Number of Hospitals in Upazila (nhsp, 0-1)\n",
    "code3_hosp = np.floor(df[df.FType == 'Hospital'].CC_4/100)\n",
    "code3_hosp = code3_hosp.value_counts()\n",
    "nhsp = np.empty(code3.shape); nhsp[:] = 0\n",
    "for index, freq in code3_hosp.iteritems():\n",
    "    nhsp[code3 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nhsp = 1 - fh.zeroToOne(nhsp)\n",
    "fh.evaluation('nhsp', nhsp, code4)\n",
    "# - Number of PHC in Union (nphc, 0-1)\n",
    "code4_phc = df[df.FType == 'Family Welfare Centre'].CC_4\n",
    "code4_phc = code4_phc.value_counts()\n",
    "nphc = np.empty(code4.shape); nphc[:] = 0\n",
    "for index, freq in code4_phc.iteritems():\n",
    "    nphc[code4 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nphc = 1 - fh.zeroToOne(nphc)\n",
    "fh.evaluation('nphc', nphc, code4)\n",
    "\n",
    "# Slope (slop, 0-1)\n",
    "fn = os.path.join('land','slope_hydrosheds','slope_wgs84.tif')\n",
    "ds = gdal.Open(fn)\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('float32')   # (728, 559)\n",
    "slop = data[1:,:]                                            # (727, 559)\n",
    "slop[slop == slop[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "slop[code4 == code4[0,0]] = 0\n",
    "slop[slop != 0] = np.log(slop[slop != 0])\n",
    "slop[slop != 0] = fh.zeroToOne(slop[slop != 0])\n",
    "fh.evaluation('slop', slop, code4)\n",
    "\n",
    "# Climate: WorldClim\n",
    "loc = os.path.join('hydrology', 'clim_worldclim')\n",
    "prec = np.empty((727,559,4)); prec[:] = np.nan\n",
    "tavg = np.empty((727,559,4)); tavg[:] = np.nan\n",
    "wind = np.empty((727,559,4)); wind[:] = np.nan\n",
    "for i in range(4):\n",
    "    # - Precipitation (prec, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'prec_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        prec[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        prec[:,:,i] = temp[:-1,1:]\n",
    "    # - Temperature (tavg, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'tavg_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        tavg[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        tavg[:,:,i] = temp[:-1,1:]\n",
    "    # - Wind (wind, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'wind_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        wind[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        wind[:,:,i] = temp[:-1,1:]\n",
    "prec = np.mean(prec, axis=2); prec = fh.climInterpolate(prec, code4)\n",
    "tavg = np.mean(tavg, axis=2); tavg = fh.climInterpolate(tavg, code4)\n",
    "wind = np.mean(wind, axis=2); wind = fh.climInterpolate(wind, code4)\n",
    "# - Scale to 0-1\n",
    "prec[code4 != code4[0,0]] = fh.zeroToOne(np.log(prec[code4 != code4[0,0]]))\n",
    "tavg[code4 != code4[0,0]] = fh.zeroToOne(tavg[code4 != code4[0,0]])\n",
    "wind[code4 != code4[0,0]] = fh.zeroToOne(wind[code4 != code4[0,0]])\n",
    "fh.evaluation('prec', prec, code4)\n",
    "fh.evaluation('tavg', tavg, code4)\n",
    "fh.evaluation('wind', wind, code4)\n",
    "\n",
    "# Elevation (elev, 0 or 1)\n",
    "# *elev <= 5: 1, elev > 5: 0\n",
    "ds = gdal.Open(os.path.join('land','dem_hydrosheds','as_dem_30s_bgd.tif'))\n",
    "elev = ds.GetRasterBand(1).ReadAsArray().astype(float)\n",
    "elev[(elev >= 0) & (elev <= 5)] = 1\n",
    "elev[(elev > 5) | (elev < 0)] = 0\n",
    "fh.evaluation('elev', elev, code4)\n",
    "\n",
    "# Poverty from WorldPop dataset\n",
    "loc = os.path.join('socioecon', 'poverty_worldpop')\n",
    "# DHS wealth score (wlth, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2011wipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "wlth = np.empty(code4.shape); wlth[:] = np.nan  # (727,559)\n",
    "wlth[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (wlth == wlth[0,0]) | (np.isnan(wlth))\n",
    "wlth[~rdx] = 1 - fh.zeroToOne(wlth[~rdx])\n",
    "wlth[rdx] = 0\n",
    "fh.evaluation('wlth', wlth, code4)\n",
    "# Poverty (povt)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013ppipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "povt = np.empty(code4.shape); povt[:] = np.nan  # (727,559)\n",
    "povt[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (povt == povt[0,0]) | (np.isnan(povt))\n",
    "povt[~rdx] = fh.zeroToOne(povt[~rdx])\n",
    "povt[rdx] = 0\n",
    "fh.evaluation('povt', povt, code4)\n",
    "# Income (incm)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013incpov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "incm = np.empty(code4.shape); incm[:] = np.nan  # (727,559)\n",
    "incm[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (incm == incm[0,0]) | (np.isnan(incm))\n",
    "incm[~rdx] = 1 - fh.zeroToOne(incm[~rdx])\n",
    "incm[rdx] = 0\n",
    "fh.evaluation('incm', incm, code4)\n",
    "\n",
    "# GDP (gdp, 0-1)\n",
    "ds = gdal.Open(os.path.join('socioecon', 'gdp_kummu', 'gdp_ppp_2015_30s_bgd.tif'))\n",
    "gdp = ds.GetRasterBand(1).ReadAsArray()         # (727,559)\n",
    "rdx = np.isnan(gdp)\n",
    "# - Scale to 0-1\n",
    "gdp[~rdx] = 1 - fh.zeroToOne( np.log(gdp[~rdx]))\n",
    "gdp[rdx] = 0\n",
    "fh.evaluation('gdp', gdp, code4)\n",
    "\n",
    "# Flood prone area (fpro, 0 or 1)\n",
    "ds = gdal.Open(os.path.join('hydrology', 'flood prone area','fpro.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (727,559)\n",
    "fpro = np.zeros(temp.shape)\n",
    "fpro[temp == 0] = 1\n",
    "fh.evaluation('fpro', fpro, code4)\n",
    "\n",
    "# Flood depth (fdep, 0-1)\n",
    "loc = os.path.join('hydrology', 'inundation_glofris')\n",
    "ds = gdal.Open(os.path.join(loc, 'rp_00010.tif'))\n",
    "fdep = ds.GetRasterBand(1).ReadAsArray().astype('float')    # (727,559)\n",
    "fdep_copy = fdep.copy()\n",
    "# - Scale to 0.5-1\n",
    "fdep[fdep != 0] = fh.zeroToOne(fdep[fdep != 0])/2 + 0.5\n",
    "fh.evaluation('fdep', fdep, code4)\n",
    "\n",
    "# Accessibility to Healthcare facilities\n",
    "# *Travel time (minutes) is categoraized to 1-7\n",
    "# *Flooded areas are defined as the category of longest travel time\n",
    "loc = os.path.join('health', 'traveltime_lged')\n",
    "# - Travel time to PHC (tphc, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'family2000_clip.tif'))    # (728,559)\n",
    "tphc = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "tphc[np.isnan(tphc)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_family_rp00010_10p_clip.tif'))\n",
    "tphc_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "tphc_flood[np.isnan(tphc_flood)] = 0\n",
    "tphc_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to PHC (aphc, 0-1)\n",
    "aphc = tphc_flood - tphc\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'aphc.tif')\n",
    "temp = aphc.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Accessibility to Hospitals (thsp, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'hospital_clip.tif'))      # (728,559)\n",
    "thsp = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "thsp[np.isnan(thsp)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_hospital_rp00010_10p_clip.tif'))\n",
    "thsp_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "thsp_flood[np.isnan(thsp_flood)] = 0\n",
    "thsp_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to Hospitals (ahsp, 0-1)\n",
    "ahsp = thsp_flood - thsp\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'ahsp.tif')\n",
    "temp = ahsp.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Scale to 0-1\n",
    "tphc = fh.zeroToOne(fh.timeToCategory(tphc)); tphc[np.isnan(tphc)] = 1\n",
    "aphc = fh.zeroToOne(fh.timeToCategory(aphc)); aphc[np.isnan(aphc)] = 1\n",
    "thsp = fh.zeroToOne(fh.timeToCategory(thsp)); thsp[np.isnan(thsp)] = 1\n",
    "ahsp = fh.zeroToOne(fh.timeToCategory(ahsp)); ahsp[np.isnan(ahsp)] = 1\n",
    "fh.evaluation('tphc', tphc, code4)\n",
    "fh.evaluation('aphc', aphc, code4)\n",
    "fh.evaluation('thsp', thsp, code4)\n",
    "fh.evaluation('ahsp', ahsp, code4)\n",
    "\n",
    "# Save files\n",
    "fn = 'data_indices'\n",
    "data = {'priv':priv,'pcsh':pcsh,'ncsh':ncsh,'nhsp':nhsp,'nphc':nphc,'slop':slop,\n",
    "        'prec':prec,'tavg':tavg,'wind':wind,'elev':elev,'wlth':wlth,'povt':povt,\n",
    "        'incm':incm,'gdp':gdp,'fpro':fpro,'tphc':tphc,'aphc':aphc,'thsp':thsp,\n",
    "        'ahsp':ahsp, 'fdep':fdep}\n",
    "np.save(fn, data)\n",
    "print('{}.npy is saved..'.format(fn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
