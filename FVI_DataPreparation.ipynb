{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flood Vulnerability Index (FVI) Data Preparation\n",
    "This notebook imports socioeconomic and physical data for FVI assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, QuantileTransformer\n",
    "import fhv\n",
    "from tabula import read_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load demographic and socio-economic data\n",
    "This section imports a variety of demographic and socio-economic data from multiple sources:\n",
    "- [Bangladesh Bureau of Statistics (BBS)](http://203.112.218.65:8008/) 2011 census data downloaded from [BBS-REDATAM](http://203.112.218.69/binbgd/RpWebEngine.exe/Portal).\n",
    "- [Bangladesh 2010 Poverty Maps (Zila Upazila)](http://203.112.218.65:8008/WebTestApplication/userfiles/Image/LatestReports/Bangladesh_ZilaUpazila_pov_est_2010.pdf) is obtained from [BBS Income, Expenditure & Poverty](http://203.112.218.65:8008/PageWebMenuContent.aspx?MenuKey=366).\n",
    "- [Bangladesh Disaster-related Statistics 2015: Climate Change and Natural Disaster Perspectives](http://203.112.218.65:8008/PageWebMenuContent.aspx?MenuKey=242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_name = [['PAGE5','pos','person','demographic','Percent of children under 5 years','upazila','BBS 2011'],\n",
    "               ['PAGE65','pos','person','demographic','Percent of elder population (65+ years)','upazila','BBS 2011'],\n",
    "               ['PFEMALE','pos','person','demographic','Percent of woman','upazila','BBS 2011'],\n",
    "               ['PRURAL','pos','house','built','Percent of households in rural areas','upazila','BBS 2011'], \n",
    "               ['PWEAKBUILT','pos','house','built','Percent of households with weak materials','upazila','BBS 2011'],\n",
    "               ['PNOWATER','pos','house','built','Percent of households without public water supply','upazila','BBS 2011'],\n",
    "               ['PNOSANITARY','pos','house','built','ercent of households without sanitary facilities','upazila','BBS 2011'],\n",
    "               ['PNOELEC','pos','house','built','Percent of households without electricity','upazila','BBS 2011'],\n",
    "               ['PDISABL','pos','person','social','Percent of population with any sort of disability','upazila','BBS 2011'],\n",
    "               ['PLITERACY','pos','person','social','Percent of population who cannot read and write','upazila','BBS 2011'],\n",
    "               ['PETHNIC','pos','person','social','Percent of ethnic population','upazila','BBS 2011'],\n",
    "               ['PRENT','pos','house','social','Percent of rented houses','upazila','BBS 2011'],\n",
    "               ['PNOEMPLOY','pos','person','economic','Percent of population without employment','upazila','BBS 2011'],\n",
    "               ['PAGRICULT','pos','person','economic','Percent of population with agricultural jobs','upazila','BBS 2011'],\n",
    "               ['PPOOR','pos','house','economic','Percentage of population below the upper poverty line','upazila','BBS 2010'],\n",
    "               ['PPOOREXTR','pos','house','economic','Percentage of population below the lower povery line','upazila','BBS 2010'],\n",
    "               ['PNOPRIEDU','pos','person','education','Percent of population without primary education','upazila','BBS 2011'],\n",
    "               ['PNOCOLLEGE','pos','person','education','Percent of population without college education','upazila','BBS 2011']\n",
    "              ]\n",
    "census_name = pd.DataFrame(census_name, columns=['Name','Sign','Type','Group','Description','Scale','Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POPULATION DATA\n",
    "df = fhv.LoadCensusBBS('./data/census2011/age 5 years group.xls')\n",
    "popu = df.sum(axis=1)\n",
    "###\n",
    "# CARIBRATE POPULATION \n",
    "###\n",
    "census = pd.DataFrame(index=df.index)\n",
    "census.index.name = 'UID'\n",
    "census['UID4'] = census.index % 10000   # Add a column of the last 4 digits of UID\n",
    "# - PAGE5: Percent of children under 5 years\n",
    "census['PAGE5'] = df[df.columns[0]]/df.sum(axis=1)\n",
    "# - PAGE65: Percent of elderly population (65+ years)\n",
    "census['PAGE65'] = df[df.columns[14:]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PFEMALE: Percent of females\n",
    "df = fhv.LoadCensusBBS('./data/census2011/sex.xls')\n",
    "census['PFEMALE'] = df['Female']/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# BUILT ENVIRONMENT\n",
    "# - PRURAL: Percent of households in rural areas\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Area of Residence.xls')\n",
    "census['PRURAL'] = df['Rural']/df.sum(axis=1)\n",
    "# - PWEAKBUILT: Percent of households with weak materials\n",
    "# (#house_Kutcha_and_Jhupri / #house_total)\n",
    "# *Pucca means high quality materials (e.g., cement or RCC)\n",
    "# *Kutcha & Jhupri means weaker materials (e.g., mud, clay, lime, or thatched)\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Type of House.xls')\n",
    "census['PWEAKBUILT'] = df[['Pucca','Semi-pucca']].sum(axis=1)/df.sum(1)\n",
    "# - PNOWATER: Percent of households without public water supply\n",
    "# *This includes \"Other\", excluding \"Tap\" and \"Tube-well\" water supply\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Source of Drinking Water.xls')\n",
    "census['PNOWATER'] = df[df.columns[-1]]/df.sum(axis=1)\n",
    "# - PNOSANITARY: Percent of households without sanitary facilities\n",
    "# *This includes \"Non-Sanitary\" and \"None\" and excludes \n",
    "# *\"Sanitary (with Water Seal)\" and \"Sanitary (no Water Seal)\"\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Toilet Facilities.xls')\n",
    "census['PNOSANITARY'] = df[df.columns[2:]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PNOELEC: Percent household without electricity\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Electricity Connection.xls')\n",
    "census['PNOELEC'] = df['No']/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# SOCIAL\n",
    "# - PDISABL: Percent of population with disability\n",
    "# *This includes all kinds of disabilities (Speech, Vision, Hearing, Physical, Mental, Autistic)\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Disability.xls')\n",
    "census['PDISABL'] = df[df.columns[1:]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PLITERACY: Percent of population who cannot read and write\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Literacy.xls')\n",
    "census['PLITERACY'] = df['No']/df.sum(axis=1)\n",
    "# - PETHNIC: Percent of ethnic population \n",
    "df = fhv.LoadCensusBBS('./data/census2011/Ethnic Population.xls')\n",
    "census['PETHNIC'] = df['Yes']/df.sum(axis=1)\n",
    "# - PRENT: Percent of rented houses\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Tenancy.xls')\n",
    "census['PRENT'] = df[['Rented', 'Rent-free']].sum(axis=1)/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# EDUCATION\n",
    "# - PNOPRIEDU: Percent of population who dont complete primary education\n",
    "# *BGD's primary education is ClassI-ClassV\n",
    "# *https://en.wikipedia.org/wiki/Education_in_Bangladesh#/media/File:BangEduSys.png\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Educational Attainment.xls')\n",
    "census['PNOPRIEDU'] = df[df.columns[:5]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PNOCOLLEGE: Percent of population who don't attend college\n",
    "census['PNOCOLLEGE'] = df[df.columns[:-4]].sum(axis=1)/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# EMPLOYMENT\n",
    "# - PNOEMPLOY: Percent of population without employment\n",
    "# *This includes \"Employed\" and \"Household Work\" and excludes \"Looking For Job\" and \"Do Not Work\"\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Activity Status.xls')\n",
    "census['PNOEMPLOY'] = df[['Looking For Job','Do Not Work']].sum(axis=1)/df.sum(axis=1)\n",
    "# - PAGRICULT : Percent of population with agricultural jobs\n",
    "df = fhv.LoadCensusBBS('./data/census2011/Employment Field.xls')\n",
    "census['PAGRICULT'] = df['Agriculture']/df.sum(axis=1)\n",
    "\n",
    "\n",
    "# POVERTY\n",
    "# Read PDF document and obtain data\n",
    "df = read_pdf('./data/socioecon/Bangladesh_ZilaUpazila_pov_est_2010.pdf', \n",
    "             pages=list(range(3,13)), multiple_tables=False,\n",
    "             pandas_options={'header': None, 'skiprows':2})\n",
    "df.columns = ['zl-code','zila-name','UID4','upz-name','PPOOREXTR','PPOOR']\n",
    "df = df.drop(['zl-code','zila-name','upz-name'], axis=1)\n",
    "# Percentage to decimal\n",
    "df[['PPOOREXTR','PPOOR']] = df[['PPOOREXTR','PPOOR']]/100\n",
    "# Here we use only 4 upazila code to match with census UID, since all 4 digits are unique! Which means\n",
    "assert len(np.unique(census.index % 10000)) == len(np.unique(df['UID4']))\n",
    "# Sorting by UID4\n",
    "df = df.set_index('UID4').sort_index()\n",
    "# Merging\n",
    "census = census.reset_index().merge(df, on='UID4').set_index('UID').drop('UID4',axis=1)\n",
    "# Reordering to be matched with census_name\n",
    "census = census[census_name['Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomalization and Save variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/data.hdf is saved.\n",
      "./data/data_table.hdf is saved.\n"
     ]
    }
   ],
   "source": [
    "data = census.copy()\n",
    "data_name = census_name.copy()\n",
    "\n",
    "# Flip signs of the indicators\n",
    "for index, row in data_name.iterrows():\n",
    "    if row['Sign'] == 'neg':\n",
    "        data[row['Name']] = -data[row['Name']].values\n",
    "    elif row['Sign'] == 'pos':\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"problem\")\n",
    "# Scaling to 0-1 with Max/Min values\n",
    "scaler = MinMaxScaler()\n",
    "data[data.columns] = scaler.fit_transform(data[data.columns], )\n",
    "\n",
    "# Save data\n",
    "if True:\n",
    "    fn = './data/data.hdf'\n",
    "    data.to_hdf(fn, 'data')\n",
    "    print('%s is saved.' % fn)\n",
    "    fn = './data/data_table.hdf'\n",
    "    data_name.to_hdf(fn, 'name')\n",
    "    print('%s is saved.' % fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load physical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load code4 and code3\n",
    "fn = os.path.join('land', 'boundary_gadm', 'gadm4_code.tif')\n",
    "ds = gdal.Open(fn); dsCopy = ds\n",
    "code4 = ds.GetRasterBand(1).ReadAsArray()\n",
    "code3 = np.floor(code4/100)\n",
    "nocode = (code4 == code4[0,0])\n",
    "\n",
    "# Load census data\n",
    "cens = np.load('data_census.npy'); cens = cens.item()\n",
    "pop = cens['pop']\n",
    "\n",
    "\n",
    "#%% Load variables\n",
    "# Proximity to rivers (priv, 0-1)\n",
    "# (1km:1, 2km:0.5, 3km:0.2, 4+km:0)\n",
    "loc = './hydrology/river_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv = np.zeros(data.shape)\n",
    "priv[data != data[0,0]] = 2\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 5\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 10\n",
    "# - Scale to 0-1\n",
    "priv = fh.zeroToOne(priv)\n",
    "fh.evaluation('priv', priv, code4)\n",
    "\n",
    "# Proximity to cyclone shelters (pcsh, 0-1)\n",
    "# (1km:0, 2km:0.33, 3km:0.67, 4+km:1)\n",
    "loc = './hydrology/shelters_cyclone_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh = np.ones(data.shape)\n",
    "pcsh[data != data[0,0]] = 2/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 1/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "pcsh = fh.zeroToOne(pcsh)\n",
    "fh.evaluation('pcsh', pcsh, code4)\n",
    "\n",
    "# Number of cyclone shelters per Upazila capita (ncsh, 0-1)\n",
    "# (#shelters in Upazila / #pop in Upazila)\n",
    "fn = os.path.join(os.path.join('hydrology','shelters_cyclone',\n",
    "                               'cyclone_shelters_gadam4.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('cyclone_shelters_gadam4')\n",
    "#cshel_cc4 = df.Div_ID*10**6 + df.Dist_ID*10**4+df.Upz_ID*10**2+df.Un_ID\n",
    "cshel_cc3 = df.Div_ID*10**4 + df.Dist_ID*10**2+df.Upz_ID\n",
    "count = cshel_cc3.value_counts()\n",
    "ncsh = np.empty(code3.shape); ncsh[:] = 0\n",
    "for index, row in count.iteritems():\n",
    "    ncsh[code3 == index] = row/pop[pop[:,0] == index,1]\n",
    "# - Scale to 0-1\n",
    "ncsh = 1 - fh.zeroToOne(ncsh)\n",
    "fh.evaluation('ncsh', ncsh, code4)\n",
    "\n",
    "# Number of PHC and Hospitals\n",
    "fn = os.path.join(os.path.join('health','healthsites_lged', 'gadm4_join.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('gadm4_join')\n",
    "# - Number of Hospitals in Upazila (nhsp, 0-1)\n",
    "code3_hosp = np.floor(df[df.FType == 'Hospital'].CC_4/100)\n",
    "code3_hosp = code3_hosp.value_counts()\n",
    "nhsp = np.empty(code3.shape); nhsp[:] = 0\n",
    "for index, freq in code3_hosp.iteritems():\n",
    "    nhsp[code3 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nhsp = 1 - fh.zeroToOne(nhsp)\n",
    "fh.evaluation('nhsp', nhsp, code4)\n",
    "# - Number of PHC in Union (nphc, 0-1)\n",
    "code4_phc = df[df.FType == 'Family Welfare Centre'].CC_4\n",
    "code4_phc = code4_phc.value_counts()\n",
    "nphc = np.empty(code4.shape); nphc[:] = 0\n",
    "for index, freq in code4_phc.iteritems():\n",
    "    nphc[code4 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nphc = 1 - fh.zeroToOne(nphc)\n",
    "fh.evaluation('nphc', nphc, code4)\n",
    "\n",
    "# Slope (slop, 0-1)\n",
    "fn = os.path.join('land','slope_hydrosheds','slope_wgs84.tif')\n",
    "ds = gdal.Open(fn)\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('float32')   # (728, 559)\n",
    "slop = data[1:,:]                                            # (727, 559)\n",
    "slop[slop == slop[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "slop[code4 == code4[0,0]] = 0\n",
    "slop[slop != 0] = np.log(slop[slop != 0])\n",
    "slop[slop != 0] = fh.zeroToOne(slop[slop != 0])\n",
    "fh.evaluation('slop', slop, code4)\n",
    "\n",
    "# Climate: WorldClim\n",
    "loc = os.path.join('hydrology', 'clim_worldclim')\n",
    "prec = np.empty((727,559,4)); prec[:] = np.nan\n",
    "tavg = np.empty((727,559,4)); tavg[:] = np.nan\n",
    "wind = np.empty((727,559,4)); wind[:] = np.nan\n",
    "for i in range(4):\n",
    "    # - Precipitation (prec, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'prec_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        prec[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        prec[:,:,i] = temp[:-1,1:]\n",
    "    # - Temperature (tavg, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'tavg_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        tavg[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        tavg[:,:,i] = temp[:-1,1:]\n",
    "    # - Wind (wind, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'wind_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        wind[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        wind[:,:,i] = temp[:-1,1:]\n",
    "prec = np.mean(prec, axis=2); prec = fh.climInterpolate(prec, code4)\n",
    "tavg = np.mean(tavg, axis=2); tavg = fh.climInterpolate(tavg, code4)\n",
    "wind = np.mean(wind, axis=2); wind = fh.climInterpolate(wind, code4)\n",
    "# - Scale to 0-1\n",
    "prec[code4 != code4[0,0]] = fh.zeroToOne(np.log(prec[code4 != code4[0,0]]))\n",
    "tavg[code4 != code4[0,0]] = fh.zeroToOne(tavg[code4 != code4[0,0]])\n",
    "wind[code4 != code4[0,0]] = fh.zeroToOne(wind[code4 != code4[0,0]])\n",
    "fh.evaluation('prec', prec, code4)\n",
    "fh.evaluation('tavg', tavg, code4)\n",
    "fh.evaluation('wind', wind, code4)\n",
    "\n",
    "# Elevation (elev, 0 or 1)\n",
    "# *elev <= 5: 1, elev > 5: 0\n",
    "ds = gdal.Open(os.path.join('land','dem_hydrosheds','as_dem_30s_bgd.tif'))\n",
    "elev = ds.GetRasterBand(1).ReadAsArray().astype(float)\n",
    "elev[(elev >= 0) & (elev <= 5)] = 1\n",
    "elev[(elev > 5) | (elev < 0)] = 0\n",
    "fh.evaluation('elev', elev, code4)\n",
    "\n",
    "# Poverty from WorldPop dataset\n",
    "loc = os.path.join('socioecon', 'poverty_worldpop')\n",
    "# DHS wealth score (wlth, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2011wipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "wlth = np.empty(code4.shape); wlth[:] = np.nan  # (727,559)\n",
    "wlth[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (wlth == wlth[0,0]) | (np.isnan(wlth))\n",
    "wlth[~rdx] = 1 - fh.zeroToOne(wlth[~rdx])\n",
    "wlth[rdx] = 0\n",
    "fh.evaluation('wlth', wlth, code4)\n",
    "# Poverty (povt)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013ppipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "povt = np.empty(code4.shape); povt[:] = np.nan  # (727,559)\n",
    "povt[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (povt == povt[0,0]) | (np.isnan(povt))\n",
    "povt[~rdx] = fh.zeroToOne(povt[~rdx])\n",
    "povt[rdx] = 0\n",
    "fh.evaluation('povt', povt, code4)\n",
    "# Income (incm)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013incpov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "incm = np.empty(code4.shape); incm[:] = np.nan  # (727,559)\n",
    "incm[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (incm == incm[0,0]) | (np.isnan(incm))\n",
    "incm[~rdx] = 1 - fh.zeroToOne(incm[~rdx])\n",
    "incm[rdx] = 0\n",
    "fh.evaluation('incm', incm, code4)\n",
    "\n",
    "# GDP (gdp, 0-1)\n",
    "ds = gdal.Open(os.path.join('socioecon', 'gdp_kummu', 'gdp_ppp_2015_30s_bgd.tif'))\n",
    "gdp = ds.GetRasterBand(1).ReadAsArray()         # (727,559)\n",
    "rdx = np.isnan(gdp)\n",
    "# - Scale to 0-1\n",
    "gdp[~rdx] = 1 - fh.zeroToOne( np.log(gdp[~rdx]))\n",
    "gdp[rdx] = 0\n",
    "fh.evaluation('gdp', gdp, code4)\n",
    "\n",
    "# Flood prone area (fpro, 0 or 1)\n",
    "ds = gdal.Open(os.path.join('hydrology', 'flood prone area','fpro.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (727,559)\n",
    "fpro = np.zeros(temp.shape)\n",
    "fpro[temp == 0] = 1\n",
    "fh.evaluation('fpro', fpro, code4)\n",
    "\n",
    "# Flood depth (fdep, 0-1)\n",
    "loc = os.path.join('hydrology', 'inundation_glofris')\n",
    "ds = gdal.Open(os.path.join(loc, 'rp_00010.tif'))\n",
    "fdep = ds.GetRasterBand(1).ReadAsArray().astype('float')    # (727,559)\n",
    "fdep_copy = fdep.copy()\n",
    "# - Scale to 0.5-1\n",
    "fdep[fdep != 0] = fh.zeroToOne(fdep[fdep != 0])/2 + 0.5\n",
    "fh.evaluation('fdep', fdep, code4)\n",
    "\n",
    "# Accessibility to Healthcare facilities\n",
    "# *Travel time (minutes) is categoraized to 1-7\n",
    "# *Flooded areas are defined as the category of longest travel time\n",
    "loc = os.path.join('health', 'traveltime_lged')\n",
    "# - Travel time to PHC (tphc, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'family2000_clip.tif'))    # (728,559)\n",
    "tphc = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "tphc[np.isnan(tphc)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_family_rp00010_10p_clip.tif'))\n",
    "tphc_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "tphc_flood[np.isnan(tphc_flood)] = 0\n",
    "tphc_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to PHC (aphc, 0-1)\n",
    "aphc = tphc_flood - tphc\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'aphc.tif')\n",
    "temp = aphc.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Accessibility to Hospitals (thsp, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'hospital_clip.tif'))      # (728,559)\n",
    "thsp = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "thsp[np.isnan(thsp)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_hospital_rp00010_10p_clip.tif'))\n",
    "thsp_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "thsp_flood[np.isnan(thsp_flood)] = 0\n",
    "thsp_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to Hospitals (ahsp, 0-1)\n",
    "ahsp = thsp_flood - thsp\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'ahsp.tif')\n",
    "temp = ahsp.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Scale to 0-1\n",
    "tphc = fh.zeroToOne(fh.timeToCategory(tphc)); tphc[np.isnan(tphc)] = 1\n",
    "aphc = fh.zeroToOne(fh.timeToCategory(aphc)); aphc[np.isnan(aphc)] = 1\n",
    "thsp = fh.zeroToOne(fh.timeToCategory(thsp)); thsp[np.isnan(thsp)] = 1\n",
    "ahsp = fh.zeroToOne(fh.timeToCategory(ahsp)); ahsp[np.isnan(ahsp)] = 1\n",
    "fh.evaluation('tphc', tphc, code4)\n",
    "fh.evaluation('aphc', aphc, code4)\n",
    "fh.evaluation('thsp', thsp, code4)\n",
    "fh.evaluation('ahsp', ahsp, code4)\n",
    "\n",
    "# Save files\n",
    "fn = 'data_indices'\n",
    "data = {'priv':priv,'pcsh':pcsh,'ncsh':ncsh,'nhsp':nhsp,'nphc':nphc,'slop':slop,\n",
    "        'prec':prec,'tavg':tavg,'wind':wind,'elev':elev,'wlth':wlth,'povt':povt,\n",
    "        'incm':incm,'gdp':gdp,'fpro':fpro,'tphc':tphc,'aphc':aphc,'thsp':thsp,\n",
    "        'ahsp':ahsp, 'fdep':fdep}\n",
    "np.save(fn, data)\n",
    "print('{}.npy is saved..'.format(fn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
