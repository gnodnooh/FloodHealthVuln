{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flood Impact Prediction (FIP) Data Preparation\n",
    "The description would be updated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from shapely.geometry import Point\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, QuantileTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import fhv\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population\n",
    "\n",
    "The [Worldpop's 100m population data](https://www.worldpop.org/geodata/summary?id=5589) is downscaled to 30m by \"QGIS > Raster > Align Rasters\" to be consistent with inundation maps. In this process, the values are rescaled according to the resolution change, which is the option of the function.\n",
    "The total population in data was 158,150,540. This is rescaled to 159,670,593 (WorldBank, 2017).\n",
    "The final population raster has decuple values (10 times larger than original values) to avoid losing populated areas in integer (uint16) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inithial downscaled file is processed by QGIS\n",
    "if False:    # This is done already\n",
    "    with rasterio.open('./data/ppp_30m.tif') as src:    # This is done by QGIS\n",
    "        data = src.read(1)\n",
    "        data[data<0] = 0                     # Since the nodata value (-99999.0) is also rescaled\n",
    "        data = data/data.sum()*159679593     # Scale to WorldBank's population\n",
    "        data = np.round(data*10).astype(rasterio.uint16)\n",
    "        profile = src.profile.copy()\n",
    "        profile.update(\n",
    "            nodata=0,\n",
    "            dtype=rasterio.uint16,\n",
    "            compress='lzw')\n",
    "        out_fn = './data/bgd_ppp_2017_30m_decuple.tif'       # This file is the reference of all rasters\n",
    "        with rasterio.open(out_fn, 'w', **profile) as dst:\n",
    "            dst.write_band(1, data)\n",
    "        print('%s is saved.' % out_fn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a shapefile of the union to raster format\n",
    "Here we convert administrative boundary polygons (shapefile) to raster format. Specifically, we burn (convert) the ID number of unions in 30m spatial resolution. The shapefile of administrative boundaries is obtained from [OCHA-HDX](https://data.humdata.org/dataset/administrative-boundaries-of-bangladesh-as-of-2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# District\n",
    "shp_fn = './data/admin_boundary/bgd_admbnda_adm2_bbs_20180410.shp'\n",
    "gdf = gpd.read_file(shp_fn)\n",
    "shp_district = gdf[gdf.columns[[3,2,8,7,-1]]].sort_values('ADM2_PCODE').reset_index(drop=True)\n",
    "# Upazila\n",
    "shp_fn = './data/admin_boundary/bgd_admbnda_adm3_bbs_20180410.shp'\n",
    "gdf = gpd.read_file(shp_fn)\n",
    "shp_upazila = gdf[gdf.columns[[3,2,8,7,-1]]].sort_values('ADM3_PCODE').reset_index(drop=True)\n",
    "# Union\n",
    "shp_fn = './data/admin_boundary/bgd_admbnda_adm4_bbs_20180410.shp'\n",
    "gdf = gpd.read_file(shp_fn)\n",
    "shp_union = gdf[gdf.columns[[3,2,8,7,-1]]].sort_values('ADM4_PCODE').reset_index(drop=True)\n",
    "if False:\n",
    "    # Save template shapfiles\n",
    "    shp_district_fn = './data/adm_district.shp'\n",
    "    shp_district.to_file(shp_district_fn)\n",
    "    print('%s is saved..' % shp_district_fn)\n",
    "    shp_upazila_fn = './data/adm_upazila.shp'\n",
    "    shp_upazila.to_file(shp_upazila_fn)\n",
    "    print('%s is saved..' % shp_upazila_fn)\n",
    "    shp_union_fn = './data/adm_union.shp'\n",
    "    shp_union.to_file(shp_union_fn)\n",
    "    print('%s is saved..' % shp_union_fn)\n",
    "    \n",
    "# Convert a Union shapefile to raster\n",
    "rst_fn = './data/bgd_ppp_2017_30m_decuple.tif'\n",
    "out_fn = './data/unid_30m.tif'\n",
    "# fhv.ConvertShapeToRaster(shp_fn, rst_fn, out_fn, fieldname='ADM4_PCODE', out_dtype=rasterio.int32)\n",
    "\n",
    "# Validate the number of unions (validated)\n",
    "if False:\n",
    "    # Number of unions from shapefile (5160)\n",
    "    nUnion1 = np.unique(gpd.read_file(shp_fn)['ADM4_PCODE']).shape[0]\n",
    "    # Number of unions from raster (5160)\n",
    "    nUnion2 = np.unique(rasterio.open(out_fn).read(1)).shape[0] - 1\n",
    "    assert nUnion1 == nUnion2, 'the numbers of unions are different'\n",
    "\n",
    "# Union ID table\n",
    "uidList = shp_union['ADM4_PCODE'].astype(rasterio.int32)\n",
    "uidList.to_hdf('./data/uidlist.hdf', 'uidList')\n",
    "\n",
    "# List indexes of cells per union (This will make the aggregation easier)\n",
    "uidx_fn = './data/uidx.npz'\n",
    "if not os.path.exists(uidx_fn):\n",
    "    start_time = time.time()\n",
    "    idun = rasterio.open('./data/unid_30m.tif').read(1)                 # Union ID\n",
    "    uidx = []\n",
    "    for i,uid in uidList.iteritems():\n",
    "        uidx.append(np.ravel_multi_index(np.where(idun==uid), idun.shape))\n",
    "        print(i)\n",
    "    # Save to numpy file\n",
    "    np.savez_compressed('./data/uidx', uidx=uidx)\n",
    "    print('elapsed_time: %ds' % (time.time() - start_time))\n",
    "else:\n",
    "    uidx = np.load(uidx_fn, allow_pickle=True)['uidx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([289002963, 289020265, 289020266, ..., 296235663, 296252964,\n",
       "       296252965]),\n",
       "       array([289158434, 289175734, 289175735, ..., 293501692, 293501693,\n",
       "       293501694]),\n",
       "       array([280645977, 280645978, 280663269, ..., 288518854, 288536157,\n",
       "       288553460]),\n",
       "       ...,\n",
       "       array([109267435, 109284737, 109284738, ..., 113558612, 113558613,\n",
       "       113558614]),\n",
       "       array([112001234, 112001235, 112018536, ..., 114579453, 114579454,\n",
       "       114579455]),\n",
       "       array([111983892, 111983893, 111983894, ..., 113437383, 113437384,\n",
       "       113437385])], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uidx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inundated areas from Sentinel-1 \n",
    "The 2017 flood inundation maps are processed and produced by ICIMOD (Mr. Kabir Uddin), for example, [August composite inundation](http://rds.icimod.org/Home/DataDetail?metadataId=34492). Daily inundations are also generated for Jul-29, Aug-12, Aug-14, and Aug-24. Here we calculate inundated area (%) of each Union.</br>There was a resolution issue for August and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICIMOD's Flood Inundation Maps (Sentinel-1)\n",
    "# The monthly composite inundation maps (April, June, August) are exported as GeoTiff format \n",
    "# using \"QGIS>Export>Save as\"\n",
    "ref_path = './data/bgd_ppp_2017_30m_decuple.tif'\n",
    "in_path = './data/flood2017aug/Flood_Apr.tif'\n",
    "out_path = './data/flood_apr_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood_Jun.tif'\n",
    "out_path = './data/flood_jun_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood_Aug.tif'\n",
    "out_path = './data/flood_aug_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "# Daily inundation maps\n",
    "in_path = './data/flood2017aug/Flood data of Bangladesh on July 29, 2017/data/bd_flood_29_jul.img'\n",
    "out_path = './data/flood_jul29_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood data of Bangladesh on Aug 12, 2017/data/bd_flood_12_aug.img'\n",
    "out_path = './data/flood_aug12_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood data of Bangladesh on Aug 15, 2017/data/bd_flood_15_aug.img'\n",
    "out_path = './data/flood_aug15_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "in_path = './data/flood2017aug/Flood data of Bangladesh on Aug 24, 2017/data/bd_flood_24_aug.img'\n",
    "out_path = './data/flood_aug24_30m.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint8,0)\n",
    "\n",
    "# FFWC's Flood Inundation Map (Sentinel-1)\n",
    "in_path = './data/flood2017aug/FFWC+S1_FloodRasters_2017/S1-2017/S1_Mosaic_clp_2_BD.tif'\n",
    "out_path = './data/flood_aug_30m_ffwc.tif'\n",
    "# fhv.ReprojectToReference(in_path,ref_path,out_path,rasterio.uint32,65536)\n",
    "\n",
    "\n",
    "# FFWC Flood Forecast (Inundation) Map issued at August-16, 2017\n",
    "in_path = './data/flood2017aug/FFWC+S1_FloodRasters_2017/2017.08.16/extract_floo1'\n",
    "out_path = './data/flood2017forecast_30m_aug16_ffwc_decuple.tif'\n",
    "##TODO: Update a function\n",
    "if False:\n",
    "    out_dtype = rasterio.uint32\n",
    "    out_nodata = 0\n",
    "    with rasterio.open(ref_path) as ref:\n",
    "            profile = ref.profile.copy()\n",
    "            profile.update(\n",
    "                dtype=out_dtype,\n",
    "                compress='lzw',\n",
    "                nodata=out_nodata)\n",
    "            with rasterio.open(in_path) as src:\n",
    "                sdata = src.read(1)\n",
    "                sdata[sdata < 0 ] = 0 \n",
    "                sdata = np.round(sdata*10).astype(out_dtype)          \n",
    "                with rasterio.open(out_path, 'w', **profile) as dst:\n",
    "                    reproject(\n",
    "                        source= sdata,\n",
    "                        destination=rasterio.band(dst, 1),\n",
    "                        src_transform=src.transform,\n",
    "                        src_crs=src.crs,\n",
    "                        dst_transform=dst.transform,\n",
    "                        dst_crs=dst.crs,\n",
    "                        resampling=Resampling.nearest)\n",
    "    print(\"%s is saved.\" % out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite inundation for 2017 August event\n",
    "Here, we make a composite inundation map which can represent overall inundated areas from the 2017 flood event.  \n",
    "The values of the composite maps represent: 1 (Perennial waterbodies), 2 (Flood inundation area), and 3 (Other)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/bgd_inun_30m.tif is saved.\n"
     ]
    }
   ],
   "source": [
    "# List of inundation maps\n",
    "mon_path = ['./data/flood_apr_30m.tif', './data/flood_jun_30m.tif', './data/flood_aug_30m.tif']\n",
    "day_path = ['./data/flood_jul29_30m.tif', './data/flood_aug12_30m.tif', './data/flood_aug15_30m.tif', './data/flood_aug24_30m.tif']\n",
    "with rasterio.open(mon_path[0]) as src:\n",
    "    data = src.read(1)\n",
    "    inun = np.zeros(data.shape, rasterio.uint8)\n",
    "    profile = src.profile.copy()\n",
    "\n",
    "# Make a composite inundation\n",
    "# - Inundated area from daily maps\n",
    "for path in day_path:\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1)\n",
    "        inun[data == 1] = 2    \n",
    "# - Inundated area from monthly maps\n",
    "ONLYAUG = True\n",
    "if not ONLYAUG: \n",
    "    # Flood inundation from all months (April, June, August)\n",
    "    for path in mon_path:\n",
    "        with rasterio.open(path) as src:\n",
    "            data = src.read(1)\n",
    "            inun[data == 2] = 2\n",
    "else:\n",
    "    # Flood inundation from only August\n",
    "    with rasterio.open(mon_path[2]) as src:\n",
    "        data = src.read(1)\n",
    "        inun[data == 2] = 2\n",
    "# - Perennial water from monthly maps\n",
    "for path in mon_path:\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1)\n",
    "        inun[data == 1] = 1\n",
    "\n",
    "# Generate a new raster file\n",
    "out_fn = './data/bgd_inun_30m.tif'\n",
    "if not os.path.exists(out_fn):\n",
    "    with rasterio.open(out_fn, 'w+', **profile) as dst:\n",
    "        dst.write_band(1, inun)\n",
    "        print('%s is saved.' % out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25801248.1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load flood impacts on public health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read demographics of the unions\n",
    "Here we extract the demographic data from the Union Statistics.pdf. The records are first converted to Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = './data/union_stats_extracted.xlsx'\n",
    "\n",
    "# Read variable from Excel file\n",
    "df = pd.read_excel(fn,sheet_name = \"touched\")\n",
    "# Union ID from the document (7754)\n",
    "union = df[~df['Union'].isna()]\n",
    "id_union = union['Division']*10**6 + union['Zila']*10**4 + union['Upazila']*10**2 + union['Union']\n",
    "id_union1 = id_union.astype(int)\n",
    "\n",
    "# Union ID from a shapefile (5158)\n",
    "gdf = gpd.read_file('./data/boundary_gadm/gadm36_BGD_4.shp')\n",
    "id_union2 = gdf['CC_4'].astype(int)\n",
    "temp = np.setdiff1d(id_union1, id_union2)\n",
    "temp.shape\n",
    "print(id_union1.head())\n",
    "print(id_union2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Type of House and Tenancy\n",
    "df = pd.read_excel('./data/union/Type of House and Tenancy.xls',\n",
    "                   skiprows=11,header=0,index_col=0,skipfooter=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Rasters\n",
    "Here, we clip global-scale rasters to Peruvian national boundary. Bangladesh UTM is {EPSG:32646}.\n",
    "1. DEM from HydroSHEDS\n",
    "2. 10-year flood inundation from GLOFRIS.\n",
    "3. Population from LandScan\n",
    "4. LandCover data from [European Space Agency (ESA)'s Climate Change Initiative (CCI)](https://cds.climate.copernicus.eu/cdsapp#!/dataset/satellite-land-cover?tab=overview)\n",
    "5. DistID (District ID of the district shapefile is converted to Raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/aligned/raw/dem30s_bgd.tif is saved.\n",
      "./data/aligned/raw/dem30s_bgd_projected.tif is saved.\n",
      "./data/aligned/raw/inundation_00010.tif is saved.\n",
      "./data/aligned/raw/popu_admin_landscan17.tif is saved.\n",
      "./data/aligned/raw/lcss_aligned.tif is saved.\n",
      "./data/aligned/raw/uzid_30s.tif is saved\n"
     ]
    }
   ],
   "source": [
    "# Bangladesh national boundary\n",
    "shp_fn = './data/boundary_gadm/gadm36_BGD_0.shp'\n",
    "crs_bgd = 'EPSG:32646'\n",
    "\n",
    "# 1. Hydroshed DEM\n",
    "# - Crop raster with Peruvian national boundary\n",
    "rst_fn = '/Users/dlee/data/gis/hydrosheds/dem_void/as_dem_30s/as_dem_30s'\n",
    "out_fn = './data/aligned/raw/dem30s_bgd.tif'\n",
    "fhv.CropRasterShape(rst_fn, shp_fn, out_fn, all_touched=False)\n",
    "# - Reproject to UTM zone 17S (EPSG:32717)\n",
    "outpath = './data/aligned/raw/dem30s_bgd_projected.tif'\n",
    "fhv.ReprojectRaster(out_fn, outpath, new_crs=crs_bgd)\n",
    "\n",
    "# 2. GLOFRIS 10-year inundation\n",
    "rst_fn = '/Users/dlee/data/inundation/glofris/inun_dynRout_RP_00010.tif'\n",
    "out_fn = './data/aligned/raw/inundation_00010.tif'\n",
    "fhv.CropRasterShape(rst_fn, shp_fn, out_fn, all_touched=False)\n",
    "\n",
    "# 3. LandScan population\n",
    "rst_fn = '/Users/dlee/data/population/landscan/LandScan Global 2017/lspop2017'\n",
    "out_fn = './data/aligned/raw/popu_admin_landscan17.tif'\n",
    "fhv.CropRasterShape(rst_fn, shp_fn, out_fn, all_touched=False)\n",
    "# Total population of Bangladeh: 149,772,364 (BBS, 2011) or 159,670,593 (WorldBank, 2017)\n",
    "with rasterio.open(out_fn) as src: \n",
    "    popu = src.read().squeeze()\n",
    "    popu17 = np.sum(popu[popu != popu[0,0]])    # 158,455,362 (LandScan, 2017)\n",
    "    \n",
    "# 4. LandCover\n",
    "# Global LandCover layer is manually clipped using QGIS to the Bangladesh national boundary\n",
    "rst_fn = '/Users/dlee/data/landcover/C3S-LC-L4-LCCS-Map-300m-P1Y-2018-v2.1.1.tif'\n",
    "out_fn = './data/aligned/raw/lcss_aligned.tif'\n",
    "fhv.CropRasterShape(rst_fn, shp_fn, out_fn, all_touched=False)\n",
    "\n",
    "# 5. UpazilaID (converting administrative boundary polygon to raster)\n",
    "shp_fn = './data/boundary_gadm/gadm36_BGD_3.shp'\n",
    "rst_fn = './data/aligned/raw/dem30s_bgd.tif'\n",
    "out_fn = './data/aligned/raw/uzid_30s.tif'\n",
    "fhv.ConvertShapeToRaster(shp_fn, rst_fn, out_fn, 'CC_3', out_dtype=rasterio.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original Codes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load code4 and code3\n",
    "fn = os.path.join('land', 'boundary_gadm', 'gadm4_code.tif')\n",
    "ds = gdal.Open(fn); dsCopy = ds\n",
    "code4 = ds.GetRasterBand(1).ReadAsArray()\n",
    "code3 = np.floor(code4/100)\n",
    "nocode = (code4 == code4[0,0])\n",
    "\n",
    "# Load census data\n",
    "cens = np.load('data_census.npy'); cens = cens.item()\n",
    "pop = cens['pop']\n",
    "\n",
    "\n",
    "#%% Load variables\n",
    "# Proximity to rivers (priv, 0-1)\n",
    "# (1km:1, 2km:0.5, 3km:0.2, 4+km:0)\n",
    "loc = './hydrology/river_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv = np.zeros(data.shape)\n",
    "priv[data != data[0,0]] = 2\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 5\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 10\n",
    "# - Scale to 0-1\n",
    "priv = fh.zeroToOne(priv)\n",
    "fh.evaluation('priv', priv, code4)\n",
    "\n",
    "# Proximity to cyclone shelters (pcsh, 0-1)\n",
    "# (1km:0, 2km:0.33, 3km:0.67, 4+km:1)\n",
    "loc = './hydrology/shelters_cyclone_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh = np.ones(data.shape)\n",
    "pcsh[data != data[0,0]] = 2/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 1/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "pcsh = fh.zeroToOne(pcsh)\n",
    "fh.evaluation('pcsh', pcsh, code4)\n",
    "\n",
    "# Number of cyclone shelters per Upazila capita (ncsh, 0-1)\n",
    "# (#shelters in Upazila / #pop in Upazila)\n",
    "fn = os.path.join(os.path.join('hydrology','shelters_cyclone',\n",
    "                               'cyclone_shelters_gadam4.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('cyclone_shelters_gadam4')\n",
    "#cshel_cc4 = df.Div_ID*10**6 + df.Dist_ID*10**4+df.Upz_ID*10**2+df.Un_ID\n",
    "cshel_cc3 = df.Div_ID*10**4 + df.Dist_ID*10**2+df.Upz_ID\n",
    "count = cshel_cc3.value_counts()\n",
    "ncsh = np.empty(code3.shape); ncsh[:] = 0\n",
    "for index, row in count.iteritems():\n",
    "    ncsh[code3 == index] = row/pop[pop[:,0] == index,1]\n",
    "# - Scale to 0-1\n",
    "ncsh = 1 - fh.zeroToOne(ncsh)\n",
    "fh.evaluation('ncsh', ncsh, code4)\n",
    "\n",
    "# Number of PHC and Hospitals\n",
    "fn = os.path.join(os.path.join('health','healthsites_lged', 'gadm4_join.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('gadm4_join')\n",
    "# - Number of Hospitals in Upazila (nhsp, 0-1)\n",
    "code3_hosp = np.floor(df[df.FType == 'Hospital'].CC_4/100)\n",
    "code3_hosp = code3_hosp.value_counts()\n",
    "nhsp = np.empty(code3.shape); nhsp[:] = 0\n",
    "for index, freq in code3_hosp.iteritems():\n",
    "    nhsp[code3 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nhsp = 1 - fh.zeroToOne(nhsp)\n",
    "fh.evaluation('nhsp', nhsp, code4)\n",
    "# - Number of PHC in Union (nphc, 0-1)\n",
    "code4_phc = df[df.FType == 'Family Welfare Centre'].CC_4\n",
    "code4_phc = code4_phc.value_counts()\n",
    "nphc = np.empty(code4.shape); nphc[:] = 0\n",
    "for index, freq in code4_phc.iteritems():\n",
    "    nphc[code4 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nphc = 1 - fh.zeroToOne(nphc)\n",
    "fh.evaluation('nphc', nphc, code4)\n",
    "\n",
    "# Slope (slop, 0-1)\n",
    "fn = os.path.join('land','slope_hydrosheds','slope_wgs84.tif')\n",
    "ds = gdal.Open(fn)\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('float32')   # (728, 559)\n",
    "slop = data[1:,:]                                            # (727, 559)\n",
    "slop[slop == slop[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "slop[code4 == code4[0,0]] = 0\n",
    "slop[slop != 0] = np.log(slop[slop != 0])\n",
    "slop[slop != 0] = fh.zeroToOne(slop[slop != 0])\n",
    "fh.evaluation('slop', slop, code4)\n",
    "\n",
    "# Climate: WorldClim\n",
    "loc = os.path.join('hydrology', 'clim_worldclim')\n",
    "prec = np.empty((727,559,4)); prec[:] = np.nan\n",
    "tavg = np.empty((727,559,4)); tavg[:] = np.nan\n",
    "wind = np.empty((727,559,4)); wind[:] = np.nan\n",
    "for i in range(4):\n",
    "    # - Precipitation (prec, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'prec_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        prec[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        prec[:,:,i] = temp[:-1,1:]\n",
    "    # - Temperature (tavg, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'tavg_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        tavg[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        tavg[:,:,i] = temp[:-1,1:]\n",
    "    # - Wind (wind, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'wind_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        wind[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        wind[:,:,i] = temp[:-1,1:]\n",
    "prec = np.mean(prec, axis=2); prec = fh.climInterpolate(prec, code4)\n",
    "tavg = np.mean(tavg, axis=2); tavg = fh.climInterpolate(tavg, code4)\n",
    "wind = np.mean(wind, axis=2); wind = fh.climInterpolate(wind, code4)\n",
    "# - Scale to 0-1\n",
    "prec[code4 != code4[0,0]] = fh.zeroToOne(np.log(prec[code4 != code4[0,0]]))\n",
    "tavg[code4 != code4[0,0]] = fh.zeroToOne(tavg[code4 != code4[0,0]])\n",
    "wind[code4 != code4[0,0]] = fh.zeroToOne(wind[code4 != code4[0,0]])\n",
    "fh.evaluation('prec', prec, code4)\n",
    "fh.evaluation('tavg', tavg, code4)\n",
    "fh.evaluation('wind', wind, code4)\n",
    "\n",
    "# Elevation (elev, 0 or 1)\n",
    "# *elev <= 5: 1, elev > 5: 0\n",
    "ds = gdal.Open(os.path.join('land','dem_hydrosheds','as_dem_30s_bgd.tif'))\n",
    "elev = ds.GetRasterBand(1).ReadAsArray().astype(float)\n",
    "elev[(elev >= 0) & (elev <= 5)] = 1\n",
    "elev[(elev > 5) | (elev < 0)] = 0\n",
    "fh.evaluation('elev', elev, code4)\n",
    "\n",
    "# Poverty from WorldPop dataset\n",
    "loc = os.path.join('socioecon', 'poverty_worldpop')\n",
    "# DHS wealth score (wlth, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2011wipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "wlth = np.empty(code4.shape); wlth[:] = np.nan  # (727,559)\n",
    "wlth[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (wlth == wlth[0,0]) | (np.isnan(wlth))\n",
    "wlth[~rdx] = 1 - fh.zeroToOne(wlth[~rdx])\n",
    "wlth[rdx] = 0\n",
    "fh.evaluation('wlth', wlth, code4)\n",
    "# Poverty (povt)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013ppipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "povt = np.empty(code4.shape); povt[:] = np.nan  # (727,559)\n",
    "povt[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (povt == povt[0,0]) | (np.isnan(povt))\n",
    "povt[~rdx] = fh.zeroToOne(povt[~rdx])\n",
    "povt[rdx] = 0\n",
    "fh.evaluation('povt', povt, code4)\n",
    "# Income (incm)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013incpov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "incm = np.empty(code4.shape); incm[:] = np.nan  # (727,559)\n",
    "incm[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (incm == incm[0,0]) | (np.isnan(incm))\n",
    "incm[~rdx] = 1 - fh.zeroToOne(incm[~rdx])\n",
    "incm[rdx] = 0\n",
    "fh.evaluation('incm', incm, code4)\n",
    "\n",
    "# GDP (gdp, 0-1)\n",
    "ds = gdal.Open(os.path.join('socioecon', 'gdp_kummu', 'gdp_ppp_2015_30s_bgd.tif'))\n",
    "gdp = ds.GetRasterBand(1).ReadAsArray()         # (727,559)\n",
    "rdx = np.isnan(gdp)\n",
    "# - Scale to 0-1\n",
    "gdp[~rdx] = 1 - fh.zeroToOne( np.log(gdp[~rdx]))\n",
    "gdp[rdx] = 0\n",
    "fh.evaluation('gdp', gdp, code4)\n",
    "\n",
    "# Flood prone area (fpro, 0 or 1)\n",
    "ds = gdal.Open(os.path.join('hydrology', 'flood prone area','fpro.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (727,559)\n",
    "fpro = np.zeros(temp.shape)\n",
    "fpro[temp == 0] = 1\n",
    "fh.evaluation('fpro', fpro, code4)\n",
    "\n",
    "# Flood depth (fdep, 0-1)\n",
    "loc = os.path.join('hydrology', 'inundation_glofris')\n",
    "ds = gdal.Open(os.path.join(loc, 'rp_00010.tif'))\n",
    "fdep = ds.GetRasterBand(1).ReadAsArray().astype('float')    # (727,559)\n",
    "fdep_copy = fdep.copy()\n",
    "# - Scale to 0.5-1\n",
    "fdep[fdep != 0] = fh.zeroToOne(fdep[fdep != 0])/2 + 0.5\n",
    "fh.evaluation('fdep', fdep, code4)\n",
    "\n",
    "# Accessibility to Healthcare facilities\n",
    "# *Travel time (minutes) is categoraized to 1-7\n",
    "# *Flooded areas are defined as the category of longest travel time\n",
    "loc = os.path.join('health', 'traveltime_lged')\n",
    "# - Travel time to PHC (tphc, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'family2000_clip.tif'))    # (728,559)\n",
    "tphc = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "tphc[np.isnan(tphc)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_family_rp00010_10p_clip.tif'))\n",
    "tphc_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "tphc_flood[np.isnan(tphc_flood)] = 0\n",
    "tphc_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to PHC (aphc, 0-1)\n",
    "aphc = tphc_flood - tphc\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'aphc.tif')\n",
    "temp = aphc.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Accessibility to Hospitals (thsp, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'hospital_clip.tif'))      # (728,559)\n",
    "thsp = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "thsp[np.isnan(thsp)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_hospital_rp00010_10p_clip.tif'))\n",
    "thsp_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "thsp_flood[np.isnan(thsp_flood)] = 0\n",
    "thsp_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to Hospitals (ahsp, 0-1)\n",
    "ahsp = thsp_flood - thsp\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'ahsp.tif')\n",
    "temp = ahsp.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Scale to 0-1\n",
    "tphc = fh.zeroToOne(fh.timeToCategory(tphc)); tphc[np.isnan(tphc)] = 1\n",
    "aphc = fh.zeroToOne(fh.timeToCategory(aphc)); aphc[np.isnan(aphc)] = 1\n",
    "thsp = fh.zeroToOne(fh.timeToCategory(thsp)); thsp[np.isnan(thsp)] = 1\n",
    "ahsp = fh.zeroToOne(fh.timeToCategory(ahsp)); ahsp[np.isnan(ahsp)] = 1\n",
    "fh.evaluation('tphc', tphc, code4)\n",
    "fh.evaluation('aphc', aphc, code4)\n",
    "fh.evaluation('thsp', thsp, code4)\n",
    "fh.evaluation('ahsp', ahsp, code4)\n",
    "\n",
    "# Save files\n",
    "fn = 'data_indices'\n",
    "data = {'priv':priv,'pcsh':pcsh,'ncsh':ncsh,'nhsp':nhsp,'nphc':nphc,'slop':slop,\n",
    "        'prec':prec,'tavg':tavg,'wind':wind,'elev':elev,'wlth':wlth,'povt':povt,\n",
    "        'incm':incm,'gdp':gdp,'fpro':fpro,'tphc':tphc,'aphc':aphc,'thsp':thsp,\n",
    "        'ahsp':ahsp, 'fdep':fdep}\n",
    "np.save(fn, data)\n",
    "print('{}.npy is saved..'.format(fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/aligned/raw/dem30s_bgd.tif is saved.\n",
      "./data/aligned/raw/dem30s_bgd_projected.tif is saved.\n",
      "./data/aligned/raw/inundation_00010.tif is saved.\n",
      "./data/aligned/raw/popu_admin_landscan17.tif is saved.\n",
      "./data/aligned/raw/lcss_aligned.tif is saved.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/aligned/raw/uzid_30s.tif is saved\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment of Rasters\n",
    "Then, we align rasters in order to match their extent and resolution. This is done manually by QGIS > Raster > Align Rasters. The raster data includes:\n",
    "1. DEM: './data/alinged/raw/dem30_peru_Projected.tif' (reference raster; UTM zone 17S (EPSG:32717))\n",
    "2. Inundation: './data/aligned/raw/inundation_00010.tif'\n",
    "3. population: './data/aligned/raw/popu_admin_landscan17.tif'\n",
    "4. LandCover: './data/aligned/raw/landcover_peru.tif'\n",
    "5. DistID: './data/aligned/raw/distid_30s.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flood Inundation Barriers\n",
    "We polygonize the cells with flood depth over 1.0m.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/aligned/polygonized/inundation_peru_1m.tif is saved.\n"
     ]
    }
   ],
   "source": [
    "# Read/Modify/Save the inundation raster\n",
    "in_ras = './data/aligned/inundation_peru.tif'\n",
    "out_ras = './data/aligned/polygonized/inundation_peru_1m.tif'\n",
    "with rasterio.open(in_ras, 'r') as src:\n",
    "    meta = src.meta.copy()\n",
    "    # Ignore cells with flood depth under 1.0 meter.\n",
    "    inun = src.read(1)\n",
    "    inun[inun < 10] = -32768\n",
    "    with rasterio.open(out_ras, 'w', **meta) as dest:\n",
    "        dest.write_band(1, inun)\n",
    "        print('%s is saved.' % out_ras)\n",
    "# The inundation raster is manually converted to shapefile (polygon) \n",
    "# by QGIS>Raster>Conversion>Polygonize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Health facilities\n",
    "We obtained the information of health facilities (location, name, level, etc.) from [GeoMINSA](http://www.geominsa.minsa.gob.pe:8080/geominsa/) as Excel format. Here, we read the data and create a shapefile of health facilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/health_facility_MINSA.shp is saved.\n",
      "data/health_facility_MINSA_all.shp is saved.\n"
     ]
    }
   ],
   "source": [
    "# Load health facilities obtained from GeoMINSA\n",
    "filn_in = os.path.join('./data/health_facility_MINSA.xls')\n",
    "df = pd.read_excel(filn_in, header=0).dropna()\n",
    "df = df.rename(columns={'Distrito':'district',\n",
    "                       'Latitud':'x',\n",
    "                       'Longitud':'y',\n",
    "                       'Categoría':'category'})\n",
    "df.head()\n",
    "# GeoDataFrame needs a shapely object\n",
    "df['Coordinates'] = list(zip(df.x, df.y))           # Coordinates\n",
    "df['Coordinates'] = df['Coordinates'].apply(Point)  # tuples to Shapely's Point\n",
    "crs = {'init': 'epsg:4326'}\n",
    "gdf = gpd.GeoDataFrame(df, crs=crs, geometry='Coordinates')\n",
    "# Exclude facilities outside of the country domain\n",
    "polygon = gpd.read_file('./data/per_admbnda_adm0_2018.shp')\n",
    "geom = polygon.geometry[0]\n",
    "gdf = gdf[gdf.within(polygon.geometry[0])]\n",
    "# Select specific types of facilities\n",
    "gdf_selected = gdf[gdf.category.isin(['I-4','II-1','II-2','II-E','III-1','III-2','III-E'])]\n",
    "# Write ESRI shapefile\n",
    "if True:\n",
    "    filn_out = os.path.join('data/health_facility_MINSA.shp')\n",
    "    gdf_selected.to_file(filn_out, encoding='utf-8')\n",
    "    print('%s is saved.' % filn_out)\n",
    "    filn_out = os.path.join('data/health_facility_MINSA_all.shp')\n",
    "    gdf.to_file(filn_out, encoding='utf-8')\n",
    "    print('%s is saved.' % filn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roads\n",
    "Roads data is obtained from [HOTOSM (OpenStreetMap) from Humnitarian Data Exchange](https://data.humdata.org/dataset/hotosm_per_roads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/road_osm.shp is saved.\n"
     ]
    }
   ],
   "source": [
    "filn_in = '/Users/dlee/data/per/roads/hotosm_per_roads_lines_shp/hotosm_per_roads_lines.shp'\n",
    "road = gpd.read_file(filn_in)\n",
    "# Select Primary, Secondary, and Tertiary roads\n",
    "road = road.loc[road['highway'].isin(['primary', 'secondary', 'tertiary'])]\n",
    "# Type and Class\n",
    "road = road.drop(['osm_id','name','surface','smoothness','width','lanes','oneway','bridge','layer','z_index'], axis=1)\n",
    "road_class = {1:'primary',2:'secondary',3:'tertiary'}\n",
    "road['class'] = 1\n",
    "road.loc[road.highway == 'secondary', 'class'] = 2\n",
    "road.loc[road.highway == 'tertiary', 'class'] = 3\n",
    "# Save\n",
    "if True:\n",
    "    filn_out = './data/road_osm.shp'\n",
    "    road.to_file(filn_out)\n",
    "    print('%s is saved.' % filn_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rivers and Wetlands\n",
    "The hydrography data of Peru is obtained from [Humanitarian Data Exchange (HDX) (Instituto Geográfico Nacional - IGN)](https://data.humdata.org/dataset/hidrografia-de-peru).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education facilities\n",
    "Education facilities is obtained from [Ministry of Education > ESCALE](http://escale.minedu.gob.pe/mapas).\n",
    "https://wenr.wes.org/2015/04/education-in-peru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessibility Analysis\n",
    "The accessibility analysis is done by using [AccessMod 5](https://www.accessmod.org/) ([AccessMod 5 manual](https://doc-accessmod.unepgrid.ch/display/EN/AccessMod+5+user+manual)).\n",
    "- Accessibility to Health facilities\n",
    "- Accessibility to Education facilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 2017 INEI Census Data\n",
    "\n",
    "This code imports 2017 Peruvian national census data and distribute to 1km x 1km grids. The original census data was obtained from the [Nathional Institute of Statistics and Information (INEI)](http://censos2017.inei.gob.pe/redatam/).\n",
    "\n",
    "- C2P1: Type of Housing (hous, 0-1)\n",
    "- PAGE5: Percent children under 5 years\n",
    "- PAGE65: Percent of elderly population (65+ years)\n",
    "- PFEMALE: Percent females\n",
    "- PDISABL: Percent population with disability\n",
    "- PMEDINS: Percent population with health insurance\n",
    "- PNOSWALL: Percent households without strong walls\n",
    "- PNOWATER: Percent households without public water supply\n",
    "- PNOELEC: Percent households without electricity\n",
    "- PNOSEWAGE: Percent households without sewage infrastructure\n",
    "- PLITERACY: Percent population who cannot read and write\n",
    "- PNOPRIEDU: Percent population who don't complete primary education\n",
    "- PNOCOLLEGE: Percent population who don't complete college degree\n",
    "- PRENT: Percentage of rented houses\n",
    "- ANUMBFAMILY: Averaged Numer of people in family\n",
    "- PPHONE: Percent households with cell phone or landline\n",
    "- PAUTOMOBILE: Percent households with automobiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_name = [['PAGE5','pos','person','Percent children under 5 years'],\n",
    "               ['PAGE65','pos','person','Percent elder population (65+ years)'],\n",
    "               ['PFEMALE','pos','person','Percent females'],\n",
    "               ['PDISABL','pos','person','Percent population with disability'],\n",
    "               ['PMEDINS','neg','person','Percent population with health insurance'],\n",
    "               ['PNOSWALL','pos','house','Percent households without strong walls'],\n",
    "               ['PNOWATER','pos','house','Percent households without public water supply'],\n",
    "               ['PNOELEC','pos','house','Percent households without electricity'],\n",
    "               ['PNOSEWAGE','pos','house','Percent households without sewage infrastructure'],\n",
    "               ['PLITERACY','pos','person','Percent population who cannot read and write'],\n",
    "               ['PNOPRIEDU','pos','person','Percent population who don''t complete primary education'],\n",
    "               ['PNOCOLLEGE','pos','person','Percent population who don''t complete college degree'],\n",
    "               ['PRENT','pos','house','Percentage of rented houses'],\n",
    "               ['ANUMBFAMILY','pos','house','Averaged Numer of people in family'],\n",
    "               ['PPHONE','neg','house','Percent households with cell phone or landline'],\n",
    "               ['PAUTOMOBILE','neg','house','Percent households with automobiles']]\n",
    "census_name = pd.DataFrame(census_name, columns=['Name','Sign','Type','Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label values is manually exported and translated\n",
    "fn_label = os.path.join('data','census','label_values.xlsx')\n",
    "\n",
    "# C2P1: Type of Housing (hous, 0-1) \n",
    "# (#house_Kutcha_and_Jhupri / #house_total)\n",
    "# *Pucca means high quality materials (e.g., cement or RCC)\n",
    "# *Kutcha & Jhupri means weaker materials (e.g., mud, clay, lime, or thatched)\n",
    "df1 = fhv.LoadCensusINEI(os.path.join('data','census','C2P1.xlsx'), fn_label)\n",
    "totalHous1 = df1.sum(axis=1).sum()\n",
    "df2 = fhv.LoadCensusINEI(os.path.join('data','census','C2P2.xlsx'), fn_label)\n",
    "totalHous2 = df2.sum(axis=1).sum()\n",
    "\n",
    "\n",
    "# POPULATION DATA\n",
    "\"\"\"\n",
    "Surveyed population:  29,381,884\n",
    "Ommited population:    1,855,501\n",
    "Total population:     31,237,385  \n",
    "\"\"\"\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','EDQUINQ.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census = pd.DataFrame(index=df.index)  # This should be located at here (#IDDIST=1873)\n",
    "popu = df.sum(axis=1)                # Total population: 29381884\n",
    "# - PAGE5 Percent children under 5 years\n",
    "census['PAGE5'] = df[df.columns[1]]/df.sum(axis=1)\n",
    "# - PAGE65: Percent of elderly population (65+ years)\n",
    "census['PAGE65'] = df[df.columns[14:]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PFEMALE: Percent females\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C5P2.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PFEMALE'] = df['Woman']/df.sum(axis=1)\n",
    "\n",
    "#########\n",
    "# Percent housholds that are female owned\n",
    "# *** DOWNLOAD ***\n",
    "#########\n",
    "\n",
    "# DISABILITY\n",
    "# - PDISABL: Percent population with disability\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','P09DISC.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PDISABL'] = 1 - df[df.columns[-1]]/df.sum(axis=1)\n",
    "\n",
    "# MEDICAL INSURANCE\n",
    "# - PMEDINS: Percent population with health insurance\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','P08AFILIA.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PMEDINS']= 1 - df[df.columns[-1]]/df.sum(axis=1)\n",
    "\n",
    "# BUILT ENVIRONMENT\n",
    "# - PNOSWALL: Percent households without strong walls\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C2P3.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "hous = df.sum(axis=1)           # Total households 7698900\n",
    "census['PNOSWALL'] = 1 - df[df.columns[1:4]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PNOWATER: Percent household without public water supply\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C2P6.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PNOWATER'] = 1 - df[df.columns[1:3]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PNOELEC: Percent household without electricity\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C2P11.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PNOELEC'] = df[df.columns[2]]/df.sum(axis=1)\n",
    "# - PNOSEWAGE: Percent household without sewage infrastructure\n",
    "# This excludes 'Public drainage network within the dwelling' and\n",
    "# 'Public drainage network outside the home, but inside the building'\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C2P10.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PNOSEWAGE']= 1 - df[df.columns[1:3]].sum(axis=1)/df.sum(axis=1)\n",
    "\n",
    "# EDUCATION\n",
    "# - PLITERACY: Percent population who cannot read and write\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C5P12.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PLITERACY'] = df[df.columns[2]]/df.sum(axis=1)\n",
    "# - PNOPRIEDU: Percent population who don't complete primary education\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C5P13NIV.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PNOPRIEDU'] = df[df.columns[1:3]].sum(axis=1)/df.sum(axis=1)\n",
    "# - PNOCOLLEGE: Percent population who don't complete college degree\n",
    "census['PNOCOLLEGE'] = df[df.columns[1:-2]].sum(axis=1)/df.sum(axis=1)\n",
    "\n",
    "# HOUSING\n",
    "# - PRENT: Percentage of rented houses\n",
    "# Includes: 'Rented', 'Assignment', 'Another way'\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C2P13.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PRENT'] = df[df.columns[[1,4,5]]].sum(axis=1)/df.sum(axis=1)\n",
    "\n",
    "# FAMILY STRUCTURE\n",
    "# - ANUMBFAMILY: Averaged Numer of people in family\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C4P1.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['ANUMBFAMILY'] = df[df.columns[1:]].values.dot(np.arange(31))/df.sum(axis=1)\n",
    "\n",
    "# SOCIOECONOMIC CHARACTERISTICS\n",
    "########\n",
    "#UPDATE: Find cross table from REDATUM\n",
    "########\n",
    "# - PPHONE: Percent households with cell phone or landline\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C3P210.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PPHONE'] = df[df.columns[1]]/df.sum(axis=1)\n",
    "# - PAUTOMOBILE: Percent households with automobiles\n",
    "df = fhv.LoadCensusINEI(os.path.join('data','census','C3P214.xlsx'), fn_label)\n",
    "df = fhv.CorrectDistrict(df, 'sum')\n",
    "census['PAUTOMOBILE'] = df[df.columns[1]]/df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 510 Dashboards data\n",
    "Community risk and Impact data from [510 Dashboards](https://dashboard.510.global/#!/) (Export > Export CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Community Risk -------------------------------------------------- #\n",
    "# Select variables from 510 Dashboards Community Risk data\n",
    "risk_name = [['NEDUFACIL','neg','infra','Nr. of educational facilities per 10,000 people'],\n",
    "             ['NHEALFACIL','neg','infra','Nr. of health facilities per 10,000 people'],\n",
    "             ['PINFANTMOR','pos','person','Infant mortality rate'],\n",
    "             ['LIFEEXPECT','neg','person','Life expectancy'],\n",
    "             ['PCHILDMAL','pos','person','% malnutrition U5 children'],\n",
    "             ['POVERTY','pos','person','Poverty incidence'],\n",
    "             ['TTCITY','neg','infra','Travel time to nearest city'],\n",
    "             ['VECTORDIS','pos','person','Vectorborne disease incidence per 10,000 people'],\n",
    "             ['WATERDIS','pos','person','Waterborne disease incidence per 10,000 people']]\n",
    "risk_name = pd.DataFrame(risk_name, columns=['Name','Sign','Type','Description'])\n",
    "# Load the selected variables\n",
    "data = pd.read_csv('./data/510_community_risk.csv', sep=';')\n",
    "risk = data[risk_name.Description]\n",
    "risk.index = data.pcode\n",
    "risk.index.name = 'IDDIST'\n",
    "risk.columns = risk_name.Name\n",
    "# Rename risk_name description\n",
    "risk_name.loc[[0,1,2,4],'Description'] = ['Number of educational facilities per 10,000 people',\n",
    "                                          'Number of health facilities per 10,000 people',\n",
    "                                          'Percent infant mortality',\n",
    "                                          'Percent child malnutrition']\n",
    "# Fill missing values (all missing values are regarded as zero)\n",
    "risk[risk.isnull()] = 0\n",
    "# Scaling for incidence variables (Quantile transform)\n",
    "scaler = QuantileTransformer()\n",
    "target = ['NEDUFACIL','NHEALFACIL','TTCITY','VECTORDIS','WATERDIS']\n",
    "risk[target] = scaler.fit_transform(risk[target])\n",
    "# Fill missing districts (simply copy nearest valid ones)\n",
    "risk = risk.reindex(census.index)\n",
    "risk = risk.fillna(method = 'ffill')\n",
    "\n",
    "\n",
    "# 2. Flood Impact ---------------------------------------------------- #\n",
    "impact_name = [['NDAMHOUS','pos','house','# of damaged houses'],\n",
    "               ['NAFFCTPPL','pos','person','# of affected people']]\n",
    "impact_name = pd.DataFrame(impact_name, columns=['Name','Sign','Type','Description'])\n",
    "# Load the selected variables\n",
    "data = pd.read_csv('./data/510_impact_database.csv', sep=';')\n",
    "impact = data[impact_name.Description]\n",
    "impact.index = data.pcode\n",
    "impact.index.name = 'IDDIST'\n",
    "impact.columns = impact_name.Name\n",
    "# Rename impact_name description\n",
    "impact_name.Description = ['Number of damaged houses', 'Number of affected people']\n",
    "# Scaling for incidence variables (Quantile transform)\n",
    "scaler = QuantileTransformer(n_quantiles=500)\n",
    "target = ['NDAMHOUS','NAFFCTPPL']\n",
    "impact[target] = scaler.fit_transform(impact[target])\n",
    "# Fill missing districts (simply copy nearest valid ones)\n",
    "impact = impact.reindex(census.index, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete district-level indicators (total 27 indicators)\n",
    "- Merge DataFrames of Census, Risk, and Impact\n",
    "- Flip signs of the indicators\n",
    "    - Swap signs of the attributes expected to have a \"negative\" affect on vulnerability.\n",
    "- Scaling to 0-1 with Max/Min values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sign</th>\n",
       "      <th>Type</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PAGE5</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent children under 5 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>PAGE65</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent elder population (65+ years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>PFEMALE</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent females</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>PDISABL</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent population with disability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>PMEDINS</td>\n",
       "      <td>neg</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent population with health insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>PNOSWALL</td>\n",
       "      <td>pos</td>\n",
       "      <td>house</td>\n",
       "      <td>Percent households without strong walls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>PNOWATER</td>\n",
       "      <td>pos</td>\n",
       "      <td>house</td>\n",
       "      <td>Percent households without public water supply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>PNOELEC</td>\n",
       "      <td>pos</td>\n",
       "      <td>house</td>\n",
       "      <td>Percent households without electricity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>PNOSEWAGE</td>\n",
       "      <td>pos</td>\n",
       "      <td>house</td>\n",
       "      <td>Percent households without sewage infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>PLITERACY</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent population who cannot read and write</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>PNOPRIEDU</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent population who dont complete primary e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>PNOCOLLEGE</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent population who dont complete college d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>PRENT</td>\n",
       "      <td>pos</td>\n",
       "      <td>house</td>\n",
       "      <td>Percentage of rented houses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>ANUMBFAMILY</td>\n",
       "      <td>pos</td>\n",
       "      <td>house</td>\n",
       "      <td>Averaged Numer of people in family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>PPHONE</td>\n",
       "      <td>neg</td>\n",
       "      <td>house</td>\n",
       "      <td>Percent households with cell phone or landline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>PAUTOMOBILE</td>\n",
       "      <td>neg</td>\n",
       "      <td>house</td>\n",
       "      <td>Percent households with automobiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>NEDUFACIL</td>\n",
       "      <td>neg</td>\n",
       "      <td>infra</td>\n",
       "      <td>Number of educational facilities per 10,000 pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>NHEALFACIL</td>\n",
       "      <td>neg</td>\n",
       "      <td>infra</td>\n",
       "      <td>Number of health facilities per 10,000 people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>PINFANTMOR</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent infant mortality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>LIFEEXPECT</td>\n",
       "      <td>neg</td>\n",
       "      <td>person</td>\n",
       "      <td>Life expectancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>PCHILDMAL</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Percent child malnutrition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>POVERTY</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Poverty incidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>TTCITY</td>\n",
       "      <td>neg</td>\n",
       "      <td>infra</td>\n",
       "      <td>Travel time to nearest city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>VECTORDIS</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Vectorborne disease incidence per 10,000 people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>WATERDIS</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Waterborne disease incidence per 10,000 people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>NDAMHOUS</td>\n",
       "      <td>pos</td>\n",
       "      <td>house</td>\n",
       "      <td>Number of damaged houses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>NAFFCTPPL</td>\n",
       "      <td>pos</td>\n",
       "      <td>person</td>\n",
       "      <td>Number of affected people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name Sign    Type  \\\n",
       "0         PAGE5  pos  person   \n",
       "1        PAGE65  pos  person   \n",
       "2       PFEMALE  pos  person   \n",
       "3       PDISABL  pos  person   \n",
       "4       PMEDINS  neg  person   \n",
       "5      PNOSWALL  pos   house   \n",
       "6      PNOWATER  pos   house   \n",
       "7       PNOELEC  pos   house   \n",
       "8     PNOSEWAGE  pos   house   \n",
       "9     PLITERACY  pos  person   \n",
       "10    PNOPRIEDU  pos  person   \n",
       "11   PNOCOLLEGE  pos  person   \n",
       "12        PRENT  pos   house   \n",
       "13  ANUMBFAMILY  pos   house   \n",
       "14       PPHONE  neg   house   \n",
       "15  PAUTOMOBILE  neg   house   \n",
       "16    NEDUFACIL  neg   infra   \n",
       "17   NHEALFACIL  neg   infra   \n",
       "18   PINFANTMOR  pos  person   \n",
       "19   LIFEEXPECT  neg  person   \n",
       "20    PCHILDMAL  pos  person   \n",
       "21      POVERTY  pos  person   \n",
       "22       TTCITY  neg   infra   \n",
       "23    VECTORDIS  pos  person   \n",
       "24     WATERDIS  pos  person   \n",
       "25     NDAMHOUS  pos   house   \n",
       "26    NAFFCTPPL  pos  person   \n",
       "\n",
       "                                          Description  \n",
       "0                      Percent children under 5 years  \n",
       "1                Percent elder population (65+ years)  \n",
       "2                                     Percent females  \n",
       "3                  Percent population with disability  \n",
       "4            Percent population with health insurance  \n",
       "5             Percent households without strong walls  \n",
       "6      Percent households without public water supply  \n",
       "7              Percent households without electricity  \n",
       "8    Percent households without sewage infrastructure  \n",
       "9        Percent population who cannot read and write  \n",
       "10  Percent population who dont complete primary e...  \n",
       "11  Percent population who dont complete college d...  \n",
       "12                        Percentage of rented houses  \n",
       "13                 Averaged Numer of people in family  \n",
       "14     Percent households with cell phone or landline  \n",
       "15                Percent households with automobiles  \n",
       "16  Number of educational facilities per 10,000 pe...  \n",
       "17      Number of health facilities per 10,000 people  \n",
       "18                           Percent infant mortality  \n",
       "19                                    Life expectancy  \n",
       "20                         Percent child malnutrition  \n",
       "21                                  Poverty incidence  \n",
       "22                        Travel time to nearest city  \n",
       "23    Vectorborne disease incidence per 10,000 people  \n",
       "24     Waterborne disease incidence per 10,000 people  \n",
       "25                           Number of damaged houses  \n",
       "26                          Number of affected people  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge DataFrames of Census, Risk, and Impact\n",
    "data_name = pd.concat([census_name, risk_name, impact_name]).reset_index(drop=True)\n",
    "data_frames = [census,risk,impact]\n",
    "data = reduce(lambda  left,right: pd.merge(left,right,on=['IDDIST'],how='outer'), data_frames)\n",
    "# Flip signs of the indicators\n",
    "for index, row in data_name.iterrows():\n",
    "    if row['Sign'] == 'neg':\n",
    "        data[row['Name']] = -data[row['Name']].values\n",
    "    elif row['Sign'] == 'pos':\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"problem\")\n",
    "# Scaling to 0-1 with Max/Min values\n",
    "scaler = MinMaxScaler()\n",
    "data[data.columns] = scaler.fit_transform(data[data.columns])\n",
    "# Save file \n",
    "if False:\n",
    "    fn = './data/DistIndicators.hdf'\n",
    "    data.to_hdf(fn, 'data')\n",
    "    print('%s is saved.' % fn)\n",
    "    fn = './data/DistIndicators_table.hdf'\n",
    "    data_name.to_hdf(fn, 'name')\n",
    "    print('%s is saved.' % fn)\n",
    "data_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load physical variables\n",
    "- Proximity to rivers\n",
    "     - We first merged all hydrography (polylines) into single shapefile (QGIS>Vector>Data Management Tools>Merge Vector Layers)\n",
    "     - Then we rasterize it (QGIS>Raster>Conversion>Rasterize)\n",
    "          - Picel Size: 924.473\n",
    "          - Extent: 463832.6140015202108771,7926421.1801450066268444, 1884747.2260907599702477,9995391.1878585517406464\n",
    "     - Proximity analysis (QGIS>Raster>Analysis>Proximity)\n",
    "- Slope\n",
    "    - We use DEM clipped with box\n",
    "    - Calculate slope using QGIS>Raster>Analysis>Slope\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical drivers names\n",
    "phys_name = [['PRRIV','neg','phys','Proximity to the rivers'],\n",
    "             ['SLOPE','pos','phys','Slope'],\n",
    "             ['ELEVATION','neg','phys','Low elevation'],\n",
    "             ['FDEPTH','pos','phys','Flood depth'],\n",
    "             ['TTHEALTH','pos','infra','Travel-time to health facilities']]\n",
    "phys_name = pd.DataFrame(phys_name, columns=['Name','Sign','Type','Description'])\n",
    "\n",
    "# Proximity to rivers (original unit: meters)\n",
    "# Scale distance: from 0km(1) to 3km(0)\n",
    "priv = rasterio.open('./data/proximity_river.tif').read(1)/1000\n",
    "priv[priv >= 3] = np.nan\n",
    "priv = 1-priv/3\n",
    "priv[np.isnan(priv)] = 0\n",
    "# fhv.GenerateRaster('./data/removable1.tif',meta.copy(),priv,new_dtype=rasterio.float32)\n",
    "\n",
    "# Slope (original unit: percent of slope)\n",
    "slope = rasterio.open('./data/slope.tif').read(1)\n",
    "slope[slope == -9999] = 0\n",
    "slope = slope/slope.max()\n",
    "\n",
    "# Elevation (original unit: meters)\n",
    "# Scale altitude: from -24m(1) to -5m(0)\n",
    "dem = rasterio.open('./data/dem_peru.tif').read(1).astype('float32')\n",
    "dem[(dem == -32768) | (dem > 5)] = np.nan\n",
    "dem = 1 - (dem + 24)/29\n",
    "dem[np.isnan(dem)] = 0\n",
    "\n",
    "# Flood depth (original unit : 10 cm)\n",
    "# Scale flood depth: from 0m(0) to 2m(1)\n",
    "fdepth = rasterio.open('./data/inundation_peru.tif').read(1).astype('float32')/10\n",
    "fdepth = fdepth/2\n",
    "fdepth[fdepth > 1] = 1\n",
    "\n",
    "# Accessibility to Health facilities\n",
    "ttheal = rasterio.open('./data/traveltime/health_noflood.tif').read(1).astype('float32')\n",
    "ttheal[ttheal < 0] = 5000\n",
    "ttheal = fhv.TTimeCategory(ttheal)\n",
    "ttheal = ttheal/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete dataset\n",
    "All variables are scaled. Here, we complete data preparation\n",
    "- Merge data table\n",
    "- Generate 2D Ndarray (col: valid cells, row: variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/variable.npy is saved..\n",
      "./data/variable_table.hdf is saved.\n"
     ]
    }
   ],
   "source": [
    "# Merge data table\n",
    "variable_name = pd.concat([data_name, phys_name]).reset_index(drop=True)\n",
    "# Load District ID\n",
    "with rasterio.open(os.path.join('data', 'distid_peru.tif')) as src:\n",
    "    did = src.read().squeeze()\n",
    "    meta = src.meta.copy()\n",
    "valid = did > 0\n",
    "valid_id = did[did >0]\n",
    "\n",
    "# Generate 2D Ndarray (col:valid cells, row:variables)\n",
    "# - District level data (census,risk,impact)\n",
    "ddata = np.zeros([valid.sum(), data_name.shape[0]]).astype('float32')\n",
    "for ic in range(data.shape[0]):\n",
    "    tid = data.iloc[ic].name\n",
    "    ddata[valid_id == tid, :] = data.iloc[ic].values\n",
    "# - Physical data\n",
    "pdata = np.vstack((priv[valid],slope[valid],dem[valid],fdepth[valid],ttheal[valid])).transpose()\n",
    "# - Merging\n",
    "variable = np.hstack((ddata,pdata))\n",
    "\n",
    "# Save variable data\n",
    "if True:\n",
    "    fn = './data/variable'\n",
    "    np.save(fn, variable)\n",
    "    print('{}.npy is saved..'.format(fn))\n",
    "    fn = './data/variable_table.hdf'\n",
    "    variable_name.to_hdf(fn, 'name')\n",
    "    print('%s is saved.' % fn)\n",
    "    fn = './data/variable_weight.xlsx'\n",
    "    variable_name.to_excel(fn)\n",
    "    print('%s is saved.' % fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archived scripts from here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribute district-level data to 1km x 1km raster format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a raster of district IDs\n",
    "with rasterio.open(os.path.join('data', 'distid_peru.tif')) as src:\n",
    "    did = src.read().squeeze()\n",
    "    meta = src.meta.copy()\n",
    "# fhv.censusToRaster('./census/page5.tif', meta, did, page5)\n",
    "# fhv.censusToRaster('./census/page5.tif', meta, did, page65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data control\n",
    "INEI data and 510 data has missing data at some districts. Here, we fill those values by taking the average value of their neighbors. This is done using the spatial weights matrix `w`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert np.isnan(data).sum().sum() == 0\n",
    "# import pysal as ps\n",
    "# w = ps.lib.weights.Queen.from_shapefile('./data/DISTRITOS.shp', idVariable='IDDIST')\n",
    "# w.transform = 'R'\n",
    "# data.loc[np.isnan(data['PAGE5'])]\n",
    "# ps.lib.weights.spatial_lag.lag_spatial(w, shp_fips.MHSEVAL_ALT)\n",
    "# dbf = ps.lib.io.open('./data/DISTRITOS.dbf')\n",
    "# iddist = dbf.by_col('IDDIST')\n",
    "# shp_fips = pd.DataFrame(dbf.by_col('IDDIST'), index=iddist)\n",
    "# shp_fips\n",
    "# print(w.n)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Automatic code for LandCover\n",
    "# from netCDF4 import Dataset\n",
    "# import rioxarray\n",
    "# import xarray\n",
    "# filn = '/Users/dlee/data/landcover/C3S-LC-L4-LCCS-Map-300m-P1Y-2018-v2.1.1.nc'\n",
    "# nc_fid = Dataset(filn, 'r')\n",
    "# # Use RioXarray\n",
    "# xds = xarray.open_dataset(filn)\n",
    "# xds.rio.set_crs(\"epsg:4326\")\n",
    "# xds[\"lccs_class\"].rio.to_raster('.\\test.tif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
