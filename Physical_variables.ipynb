{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Physical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst = rasterio.open('./data/flood2017forecast_30m_aug16_ffwc_decuple.tif').read(1)  # Flood depth (decuple)\n",
    "# fcst = np.array(fcst >= 20).astype(np.int8).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors as colors\n",
    "from rasterio.plot import plotting_extent\n",
    "import seaborn as sns\n",
    "import fiona\n",
    "from descartes import PolygonPatch\n",
    "sns.set(font_scale=1.5, style=\"white\")\n",
    "\n",
    "\n",
    "## TODO: Overlay shapefile on the raster map\n",
    "\n",
    "\n",
    "\n",
    "# Define the colors\n",
    "class_bin = np.array([0,1.01,3,9,18,36,100])\n",
    "class_label = ['Flood Free','0.1-0.3 m','0.3-0.9 m','0.9-1.8 m','1.8-3.6 m','Above 3.6 m']\n",
    "class_rgb = [[222,254,190],[188,205,247],[134,177,252],[65,109,251],[54,91,224],[45,76,157]]\n",
    "class_rgb = list(np.array(class_rgb)/255)\n",
    "cmap = ListedColormap(class_rgb)\n",
    "cmap.name = class_label\n",
    "# Define a normalization from values -> colors\n",
    "norm = colors.BoundaryNorm(class_bin, len(class_bin))\n",
    "\n",
    "# Plot raster\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(10,7), facecolor='w')\n",
    "im = ax.imshow(fcst,cmap=cmap,norm=norm)\n",
    "# Title\n",
    "ax.set_title(\"FFWC Flood Inundation\")\n",
    "# Legend\n",
    "patches = [ mpatches.Patch(color=class_rgb[i],label=class_label[i]) for i in range(len(class_label)) ]\n",
    "ax.legend(handles=patches,bbox_to_anchor=(1.5, 1),facecolor=\"white\")\n",
    "# Post-setting\n",
    "plt.tight_layout()\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load code4 and code3\n",
    "fn = os.path.join('land', 'boundary_gadm', 'gadm4_code.tif')\n",
    "ds = gdal.Open(fn); dsCopy = ds\n",
    "code4 = ds.GetRasterBand(1).ReadAsArray()\n",
    "code3 = np.floor(code4/100)\n",
    "nocode = (code4 == code4[0,0])\n",
    "\n",
    "# Load census data\n",
    "cens = np.load('data_census.npy'); cens = cens.item()\n",
    "pop = cens['pop']\n",
    "\n",
    "\n",
    "#%% Load variables\n",
    "# Proximity to rivers (priv, 0-1)\n",
    "# (1km:1, 2km:0.5, 3km:0.2, 4+km:0)\n",
    "loc = './hydrology/river_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv = np.zeros(data.shape)\n",
    "priv[data != data[0,0]] = 2\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 5\n",
    "ds = gdal.Open(os.path.join(loc, 'rivers_nrel_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "priv[data != data[0,0]] = 10\n",
    "# - Scale to 0-1\n",
    "priv = fh.zeroToOne(priv)\n",
    "fh.evaluation('priv', priv, code4)\n",
    "\n",
    "# Proximity to cyclone shelters (pcsh, 0-1)\n",
    "# (1km:0, 2km:0.33, 3km:0.67, 4+km:1)\n",
    "loc = './hydrology/shelters_cyclone_proximity'\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_3km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh = np.ones(data.shape)\n",
    "pcsh[data != data[0,0]] = 2/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_2km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 1/3\n",
    "ds = gdal.Open(os.path.join(loc, 'cyclone_1km.tif'))\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('uint32')\n",
    "pcsh[data != data[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "pcsh = fh.zeroToOne(pcsh)\n",
    "fh.evaluation('pcsh', pcsh, code4)\n",
    "\n",
    "# Number of cyclone shelters per Upazila capita (ncsh, 0-1)\n",
    "# (#shelters in Upazila / #pop in Upazila)\n",
    "fn = os.path.join(os.path.join('hydrology','shelters_cyclone',\n",
    "                               'cyclone_shelters_gadam4.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('cyclone_shelters_gadam4')\n",
    "#cshel_cc4 = df.Div_ID*10**6 + df.Dist_ID*10**4+df.Upz_ID*10**2+df.Un_ID\n",
    "cshel_cc3 = df.Div_ID*10**4 + df.Dist_ID*10**2+df.Upz_ID\n",
    "count = cshel_cc3.value_counts()\n",
    "ncsh = np.empty(code3.shape); ncsh[:] = 0\n",
    "for index, row in count.iteritems():\n",
    "    ncsh[code3 == index] = row/pop[pop[:,0] == index,1]\n",
    "# - Scale to 0-1\n",
    "ncsh = 1 - fh.zeroToOne(ncsh)\n",
    "fh.evaluation('ncsh', ncsh, code4)\n",
    "\n",
    "# Number of PHC and Hospitals\n",
    "fn = os.path.join(os.path.join('health','healthsites_lged', 'gadm4_join.xlsx'))\n",
    "df = pd.ExcelFile(fn).parse('gadm4_join')\n",
    "# - Number of Hospitals in Upazila (nhsp, 0-1)\n",
    "code3_hosp = np.floor(df[df.FType == 'Hospital'].CC_4/100)\n",
    "code3_hosp = code3_hosp.value_counts()\n",
    "nhsp = np.empty(code3.shape); nhsp[:] = 0\n",
    "for index, freq in code3_hosp.iteritems():\n",
    "    nhsp[code3 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nhsp = 1 - fh.zeroToOne(nhsp)\n",
    "fh.evaluation('nhsp', nhsp, code4)\n",
    "# - Number of PHC in Union (nphc, 0-1)\n",
    "code4_phc = df[df.FType == 'Family Welfare Centre'].CC_4\n",
    "code4_phc = code4_phc.value_counts()\n",
    "nphc = np.empty(code4.shape); nphc[:] = 0\n",
    "for index, freq in code4_phc.iteritems():\n",
    "    nphc[code4 == index] = freq\n",
    "# - Scale to 0-1\n",
    "nphc = 1 - fh.zeroToOne(nphc)\n",
    "fh.evaluation('nphc', nphc, code4)\n",
    "\n",
    "# Slope (slop, 0-1)\n",
    "fn = os.path.join('land','slope_hydrosheds','slope_wgs84.tif')\n",
    "ds = gdal.Open(fn)\n",
    "data = ds.GetRasterBand(1).ReadAsArray().astype('float32')   # (728, 559)\n",
    "slop = data[1:,:]                                            # (727, 559)\n",
    "slop[slop == slop[0,0]] = 0\n",
    "# - Scale to 0-1\n",
    "slop[code4 == code4[0,0]] = 0\n",
    "slop[slop != 0] = np.log(slop[slop != 0])\n",
    "slop[slop != 0] = fh.zeroToOne(slop[slop != 0])\n",
    "fh.evaluation('slop', slop, code4)\n",
    "\n",
    "# Climate: WorldClim\n",
    "loc = os.path.join('hydrology', 'clim_worldclim')\n",
    "prec = np.empty((727,559,4)); prec[:] = np.nan\n",
    "tavg = np.empty((727,559,4)); tavg[:] = np.nan\n",
    "wind = np.empty((727,559,4)); wind[:] = np.nan\n",
    "for i in range(4):\n",
    "    # - Precipitation (prec, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'prec_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        prec[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        prec[:,:,i] = temp[:-1,1:]\n",
    "    # - Temperature (tavg, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'tavg_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        tavg[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        tavg[:,:,i] = temp[:-1,1:]\n",
    "    # - Wind (wind, 0-1)\n",
    "    ds = gdal.Open(os.path.join(loc,'wind_%02d.tif' % (i+6)))\n",
    "    temp = ds.GetRasterBand(1).ReadAsArray()\n",
    "    if temp.shape == (728, 559):\n",
    "        wind[:,:,i] = temp[1:,:]\n",
    "    elif temp.shape == (728, 560):\n",
    "        wind[:,:,i] = temp[:-1,1:]\n",
    "prec = np.mean(prec, axis=2); prec = fh.climInterpolate(prec, code4)\n",
    "tavg = np.mean(tavg, axis=2); tavg = fh.climInterpolate(tavg, code4)\n",
    "wind = np.mean(wind, axis=2); wind = fh.climInterpolate(wind, code4)\n",
    "# - Scale to 0-1\n",
    "prec[code4 != code4[0,0]] = fh.zeroToOne(np.log(prec[code4 != code4[0,0]]))\n",
    "tavg[code4 != code4[0,0]] = fh.zeroToOne(tavg[code4 != code4[0,0]])\n",
    "wind[code4 != code4[0,0]] = fh.zeroToOne(wind[code4 != code4[0,0]])\n",
    "fh.evaluation('prec', prec, code4)\n",
    "fh.evaluation('tavg', tavg, code4)\n",
    "fh.evaluation('wind', wind, code4)\n",
    "\n",
    "# Elevation (elev, 0 or 1)\n",
    "# *elev <= 5: 1, elev > 5: 0\n",
    "ds = gdal.Open(os.path.join('land','dem_hydrosheds','as_dem_30s_bgd.tif'))\n",
    "elev = ds.GetRasterBand(1).ReadAsArray().astype(float)\n",
    "elev[(elev >= 0) & (elev <= 5)] = 1\n",
    "elev[(elev > 5) | (elev < 0)] = 0\n",
    "fh.evaluation('elev', elev, code4)\n",
    "\n",
    "# Poverty from WorldPop dataset\n",
    "loc = os.path.join('socioecon', 'poverty_worldpop')\n",
    "# DHS wealth score (wlth, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2011wipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "wlth = np.empty(code4.shape); wlth[:] = np.nan  # (727,559)\n",
    "wlth[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (wlth == wlth[0,0]) | (np.isnan(wlth))\n",
    "wlth[~rdx] = 1 - fh.zeroToOne(wlth[~rdx])\n",
    "wlth[rdx] = 0\n",
    "fh.evaluation('wlth', wlth, code4)\n",
    "# Poverty (povt)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013ppipov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "povt = np.empty(code4.shape); povt[:] = np.nan  # (727,559)\n",
    "povt[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (povt == povt[0,0]) | (np.isnan(povt))\n",
    "povt[~rdx] = fh.zeroToOne(povt[~rdx])\n",
    "povt[rdx] = 0\n",
    "fh.evaluation('povt', povt, code4)\n",
    "# Income (incm)\n",
    "ds = gdal.Open(os.path.join(loc, 'bgd2013incpov_shifted.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (707,560)\n",
    "incm = np.empty(code4.shape); incm[:] = np.nan  # (727,559)\n",
    "incm[:706,:] = temp[1:,:-1]\n",
    "# - Scale to 0-1\n",
    "rdx = (incm == incm[0,0]) | (np.isnan(incm))\n",
    "incm[~rdx] = 1 - fh.zeroToOne(incm[~rdx])\n",
    "incm[rdx] = 0\n",
    "fh.evaluation('incm', incm, code4)\n",
    "\n",
    "# GDP (gdp, 0-1)\n",
    "ds = gdal.Open(os.path.join('socioecon', 'gdp_kummu', 'gdp_ppp_2015_30s_bgd.tif'))\n",
    "gdp = ds.GetRasterBand(1).ReadAsArray()         # (727,559)\n",
    "rdx = np.isnan(gdp)\n",
    "# - Scale to 0-1\n",
    "gdp[~rdx] = 1 - fh.zeroToOne( np.log(gdp[~rdx]))\n",
    "gdp[rdx] = 0\n",
    "fh.evaluation('gdp', gdp, code4)\n",
    "\n",
    "# Flood prone area (fpro, 0 or 1)\n",
    "ds = gdal.Open(os.path.join('hydrology', 'flood prone area','fpro.tif'))\n",
    "temp = ds.GetRasterBand(1).ReadAsArray()        # (727,559)\n",
    "fpro = np.zeros(temp.shape)\n",
    "fpro[temp == 0] = 1\n",
    "fh.evaluation('fpro', fpro, code4)\n",
    "\n",
    "# Flood depth (fdep, 0-1)\n",
    "loc = os.path.join('hydrology', 'inundation_glofris')\n",
    "ds = gdal.Open(os.path.join(loc, 'rp_00010.tif'))\n",
    "fdep = ds.GetRasterBand(1).ReadAsArray().astype('float')    # (727,559)\n",
    "fdep_copy = fdep.copy()\n",
    "# - Scale to 0.5-1\n",
    "fdep[fdep != 0] = fh.zeroToOne(fdep[fdep != 0])/2 + 0.5\n",
    "fh.evaluation('fdep', fdep, code4)\n",
    "\n",
    "# Accessibility to Healthcare facilities\n",
    "# *Travel time (minutes) is categoraized to 1-7\n",
    "# *Flooded areas are defined as the category of longest travel time\n",
    "loc = os.path.join('health', 'traveltime_lged')\n",
    "# - Travel time to PHC (tphc, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'family2000_clip.tif'))    # (728,559)\n",
    "tphc = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "tphc[np.isnan(tphc)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_family_rp00010_10p_clip.tif'))\n",
    "tphc_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "tphc_flood[np.isnan(tphc_flood)] = 0\n",
    "tphc_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to PHC (aphc, 0-1)\n",
    "aphc = tphc_flood - tphc\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'aphc.tif')\n",
    "temp = aphc.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Accessibility to Hospitals (thsp, 0-1)\n",
    "ds = gdal.Open(os.path.join(loc, 'hospital_clip.tif'))      # (728,559)\n",
    "thsp = ds.GetRasterBand(1).ReadAsArray()[1:,:]              # (727,559)\n",
    "thsp[np.isnan(thsp)] = 0\n",
    "ds = gdal.Open(os.path.join(loc, 'travel_hospital_rp00010_10p_clip.tif'))\n",
    "thsp_flood = ds.GetRasterBand(1).ReadAsArray()[1:,:]        # (727,559)\n",
    "thsp_flood[np.isnan(thsp_flood)] = 0\n",
    "thsp_flood[(fdep_copy >= 10)] = 2000    # Max travel time to flooded area\n",
    "# - Additional travel time to Hospitals (ahsp, 0-1)\n",
    "ahsp = thsp_flood - thsp\n",
    "# - Saving ATT to PHC (mins)\n",
    "fn = os.path.join('health', 'traveltime_lged', 'ahsp.tif')\n",
    "temp = ahsp.copy(); temp[nocode | np.isnan(temp)] = -9999\n",
    "out_ds = fh.make_raster(dsCopy, fn, temp, gdal.GDT_Float32, -9999); del out_ds\n",
    "# - Scale to 0-1\n",
    "tphc = fh.zeroToOne(fh.timeToCategory(tphc)); tphc[np.isnan(tphc)] = 1\n",
    "aphc = fh.zeroToOne(fh.timeToCategory(aphc)); aphc[np.isnan(aphc)] = 1\n",
    "thsp = fh.zeroToOne(fh.timeToCategory(thsp)); thsp[np.isnan(thsp)] = 1\n",
    "ahsp = fh.zeroToOne(fh.timeToCategory(ahsp)); ahsp[np.isnan(ahsp)] = 1\n",
    "fh.evaluation('tphc', tphc, code4)\n",
    "fh.evaluation('aphc', aphc, code4)\n",
    "fh.evaluation('thsp', thsp, code4)\n",
    "fh.evaluation('ahsp', ahsp, code4)\n",
    "\n",
    "# Save files\n",
    "fn = 'data_indices'\n",
    "data = {'priv':priv,'pcsh':pcsh,'ncsh':ncsh,'nhsp':nhsp,'nphc':nphc,'slop':slop,\n",
    "        'prec':prec,'tavg':tavg,'wind':wind,'elev':elev,'wlth':wlth,'povt':povt,\n",
    "        'incm':incm,'gdp':gdp,'fpro':fpro,'tphc':tphc,'aphc':aphc,'thsp':thsp,\n",
    "        'ahsp':ahsp, 'fdep':fdep}\n",
    "np.save(fn, data)\n",
    "print('{}.npy is saved..'.format(fn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
